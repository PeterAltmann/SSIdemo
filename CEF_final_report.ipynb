{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf071a23-adc2-4c27-8bde-57314b581ebb",
   "metadata": {},
   "source": [
    "Getting ready to work with the European Blockchain Services Infrastructure (EBSI)\n",
    "=============="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822a0561-65d0-4281-b7e5-7df48d87c80f",
   "metadata": {},
   "source": [
    "<img src=\"https://ec.europa.eu/regional_policy/sources/information/logos_downloadcenter/eu_funded_en.jpg\" alt=\"Funding acknowledgement for EU\" width=\"200\">\n",
    "\n",
    "This text is focused on facilitating a dialogue between IT staff / developers and decision makers in organizations. To help the former, the text provides a step by step guide on the use of various tools, libraries and reusable components in order to learn about user controlled authentic data (UCAD) exchanges. The text also introduces and explains the European Blockchain Services Infrastructure (EBSI), which aims to provide a Verifiable Data Registry (VDR) that is jointly maintained and support by the member states to support UCAD. Relatedly, to help decision makers, the text provides an overview of core concepts and helps explain how the various parts of the solution contribute to enabling UCAD. The text will also include tips and suggestions from the past two years of experience working with EBSI, the Toolbox project, and with the Proof of Business project at Bolagsverket."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a663e57d-1693-4b95-9d85-7c48dd2fe2cb",
   "metadata": {
    "tags": []
   },
   "source": [
    "# About this learning material"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33808f53-b179-478d-b3de-b0a6b2c547dd",
   "metadata": {},
   "source": [
    "Our increasingly digital world is fueled by data. In this emerging data driven world, trust is a key challenge. Trust means \n",
    "\n",
    "1. ensuring data security and data privacy, \n",
    "2. having data that is easy to verify, \n",
    "3. making difficult attempts to forge and tamper with data data and data records, and \n",
    "4. ensuring that the data subject is in sole and total control over their own data. \n",
    "\n",
    "To distinguish between data exchanges that satisfy these four points and those that do not, this text will refer to the former using the term 'user controlled authentic data' (UCAD). Authentic data, in this context, is a set of claims (assertions) stated by the issuer to the holder (in the form of a verifiable credential), that the holder can later prove were said by the issuer to the holder, were not tampered with and have not been revoked. New technologies like those introduced by the European Blockchain Services Infrastructure (EBSI), i.e., distributed ledgers (DLT), and work on Verifiable Credential (VC) formats and proof mechanisms, are all enabling UCAD."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8470c78-653e-4ec9-87b6-a5c4d6d6e71d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## The focus, aim, and an outline of assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d37b5ae-7120-44b8-a60c-87e1ad12cf60",
   "metadata": {},
   "source": [
    "To understand this text on VC and the EBSI, it is helpful to clarify a few points:\n",
    "\n",
    "1. This text is focused on facilitating a dialogue between IT staff (specialists and developers) and decision makers (who may or may not have a technical background). Consequently, the text will focus on both technical topics and the implications of certain technical choices for decision makers.\n",
    "2. The assumed context is the public sector. While most parts in the text are context agnostic, the focus on EBSI merits a specific focus on the public sector context.\n",
    "3. The text was developed following experiences working with VC and EBSI in the Swedish public sector, more specifically with The Swedish Company Registration Offices.\n",
    "4. The aim is to let developers get hands on experience with key concepts so that they can get familiar with VC and supporting infrastructure.\n",
    "\n",
    "The motivation for the focus on facilitating a dialogue between IT staff and decision makers was that there already exists educational material on EBSI and on VC targeting either a general audience (cf. the three chapter EBSI Explained series found [here](https://ec.europa.eu/digital-building-blocks/wikis/display/EBSI/What+is+ebsi)) or a technical audience (cf. the [W3C specifications for Verifiable Credentials data model](https://www.w3.org/TR/vc-data-model/), the Linux Foundation [LFS173x course](https://training.linuxfoundation.org/training/becoming-a-hyperledger-aries-developer-lfs173/) on becoming an Aries developer, and/or the [EBSI demonstrator](https://ec.europa.eu/digital-building-blocks/wikis/display/EBSIDOC/Demonstrator)). However, the VC concept and the infrastructure it relies on (e.g., EBSI) represent (at least in parts) fundamental shifts in how data is managed. And to fully understand these shifts and to realize many of the potential benefits with VC and EBSI, it is important that both technical staff understand the technical requirements and that non technical decision makers are equipped with the required knowledge to allow them to assess the merits of proposed uses of the technology (with a focus on helping decision makers avoid improper uses).\n",
    "\n",
    "The reason for the public sector focus is due to EBSI. Specifically, the EBSI is a joint initiative from the European Commission and the European Blockchain Partnership with the aim to leverage blockchain to accelerate the creation of cross-border services for public administrations and their ecosystems to verify information and to make services more trustworthy (cf. the [EBP page](https://digital-strategy.ec.europa.eu/en/policies/blockchain-partnership)). It is the focus of EBSI on public administration and public services that motives the focus on the public sector context in this text. Arguably, this context focus does not impact the VC parts of this text. Perhaps the biggest impact is on the adversarial assumptions and how these impact the underlying infrastructure choices of EBSI, which in turn, impacts how trust is established in VC based data exchanges.\n",
    "\n",
    "The reason for the focus on the experiences of the Swedish Company Registration Offices is due to interest. This text was developed as the end result of a CEF project on EBSI training. Early efforts in the project aimed to map the interest for EBSI and VCs in the Swedish public sector. This mapping exercise revealed that the interest in the Swedish public sector was on a rather general level. The notable exception was the Swedish Company Registration Offices (hereafter referred to by their Swedish name Bolagsverket). Bolagsverket had a strategy to decentralize information flows related to organizations and a vision to let the organizations be in control of their respective flows. Bolagsverket also wanted to explore EBSI and to learn how to leverage the infrastructure's capabilities to deliver public services. Finally, Bolagsverket had other blockchain initiatives and a project focused on VC and EBSI would reach a broad audience in the Swedish public sector since many actors follow closely the work Bolagsverket does. \n",
    "\n",
    "Finally, the aim to improve knowledge though hands on experience means that large portions of this text will be developed around mature projects that developers can use as a foundation for testing and trailing UCAD. This means that most of the exercises and the work done here will leverage the following three Hyperledger open source projects: [Aries](https://www.hyperledger.org/use/aries), [Ursa](https://www.hyperledger.org/use/ursa), and [Indy](https://www.hyperledger.org/use/hyperledger-indy). Together, these projects provide libraries, tools, and reusable components for creating decentralized applications for UCAD. Most major enterprise focused UCAD projects today leverage the three Hyperledger projects (e.g., the [Hyperledger Labs project Business Partner Agent](https://github.com/hyperledger-labs/business-partner-agent) and the [OrgBook BC project](https://www.orgbook.gov.bc.ca/search) that has issued over 4 million VCs to date) and there is extensive documentation and developer support and training. In particular, Aries helps developers work with different VC formats and the protocols required to establish secure connections and to exchange UCAD. In turn, Ursa is a cryptographic library that supports certain cryptographic primitives and algorithms that are specifically designed with user privacy in mind. Finally, Indy provides the required infrastructure to anchor trust in a decentralized and verifiable data registry. This fourth point is particularly relevant to discuss as it represents a compromise between developer friendly material and relevance for decision makers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacf8712-b89f-4933-a3f6-086a72d15f33",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Learning with the Hyperledger projects Aries, Ursa, and Indy: Benefits and words of caution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a80016-ce74-43bf-9cc5-4e111b09e3f3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "The needs of IT staff and developers trying to learn about VC and DLT differ from that of decision makers. The examples in this text are mainly based on the three aforementioned Hyperledger projects Aries, Ursa, and Indy. The reason for this choice is twofold. The three Hyperledger projects are comparatively far more mature than EBSI and its VC ecosystem. Together, the projects have over 44 000 commits from 650 code contributors (for up to date information use https://insights.lfx.linuxfoundation.org/projects/health). Furthermore, the three Hyperledger projects have been used as a foundation for several large scale pilots and many organizations have relied on them for their trial and proof of concept needs. And the choice of DLT specifically, or verifiable data registry (VDR) in general, is not necessarily an important consideration for developers or policy makers attempting to understand UCAD. What matters is that there exists a VDR that can act as a trust anchor. This text is focused on helping IT staff and developers communicate with decision makers, and the communication regarding the choice of VDR is rather trivial for IT staff and developers (often as simple as changing a few lines in a configuration file or picking a certain API and using the right access tokens, neither is important for understanding VC and EBSI).\n",
    "\n",
    "In essence, focusing on Aries, Ursa, and Indy allows developers to quickly develop and test VC solutions for UCAD. This includes:\n",
    "\n",
    "* Establishing and managing secure connections between entities without having to rely on central servers or passwords\n",
    "* Send and receive messages with high security and privacy\n",
    "* Request and obtain, store, select, combine and share, the attribute attestations necessary for consuming a services\n",
    "* Create an agent that represents the identity subject in the cloud or on edge devices\n",
    "* Manage authorizations and cryptographic key material\n",
    "\n",
    "There are, however, certain contextual factors that make the a focus on the three Hyperledger projects questionable. Perhaps most important is that [Verifiable Credentials come in many flavors](https://www.lfph.io/wp-content/uploads/2021/04/Verifiable-Credentials-Flavors-Explained-Infographic.pdf). The ones initially developed for Aries were developed with a strong emphasis on privacy. And this strong privacy focus was realized using relatively complex cryptography. For the private sector, the adversarial assumptions may warrant such a high focus on privacy for UCAD exchanges. But for the public sector, using complex cryptography has several limitations and it is arguable that the costs are worthwhile considering how the public sector context is a very different adversarial environment than is the private sector. It is questionable to assume a malicious public actor since these actors are often the authorized sources of UCAD and the principle providers of services and infrastructure. \n",
    "\n",
    "For the public sector, it makes a lot more sense to optimize for ease of implementation and to use cryptography that public sector actors are very familiar with. Especially considering how both EBSI and the ongoing work in the common union Toolbox for a coordinated effort toward a European digital identity framework (cf. [C/2021/3968](https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A32021H0946)) are likely to focus on UCAD enabled using less complex cryptography (e.g., [EBSI only requires ES256](https://ec.europa.eu/digital-building-blocks/wikis/display/EBSIDOC/E-signing+and+e-sealing+Verifiable+Credentials+and+Verifiable+Presentations), which is [basic ECDSA with P-256 and SHA-256](https://ldapwiki.com/wiki/ES256)). Consequently, the text herein will more elaborately explain how to enable UCAD using ES256 and focus more on the technologies that both the Toolbox group and the EBSI group is emphasizing for use in the public sector.\n",
    "\n",
    "Another important consideration is that EBSI is a DLT agnostic platform. At the writing of this document, EBSI supports two DLTs: [Hyperledger Besu](https://www.hyperledger.org/use/besu) and [Hyperledger Fabric](https://www.hyperledger.org/use/fabric). Besu is an Ethereum client specifically designed for enterprise and consortium environments. Since this text is educational, ease of use is prioritized. Using a general purpose DLT like Ethereum is less attractive than using a DLT purpose built for VC support and UCAD. \n",
    "\n",
    "Hyperledger Indy is a DLT similar to Hyperledger Fabric, but unlike Fabric's general purpose focus, Indy is designed specifically for UCAD. So, while EBSI does not support an Indy based ledger, it is easier to use an Indy based DLT as a VDR for learning purposes. The alternative is to: 1) develop the necessary functionality using a development environment for Ethereum, or 2) wait for EBSI to become production ready with full feature support. And while the work is rapidly progressing, and the list of [EBSI conformant wallets](https://ec.europa.eu/digital-building-blocks/wikis/display/EBSI/Conformant+wallets) keeps growing, there is still a lot of features missing on EBSI. Also, most EBSI conformant wallets are still focused on Desktop and/or mobile and not server environments, the latter being more suitable for our organization focused context. Also, the test suites for EBSI, the wallets, and the conformance tests are far less suitable for development and learning than their Aries equivalents. \n",
    "\n",
    "Aries thus offers both a solution for Enterprise environments called [Hyperledger Aries Cloud Agent Python](https://github.com/hyperledger/aries-cloudagent-python), or ACA-Py for short, and simpler [interoperability testing](https://aries-interop.info/acapy.html). It is also far more mature and most enterprise tests have been developed using ACA-Py. A few words of caution are in order here:\n",
    "\n",
    "* Most Aries based implementations do not support any of the formats and proof mechanisms that EBSI currently supports. Aries initially focused on supporting the AnonCreds VC format and relied on Indy as a VDR. In Q4 2020, focus shifted to also support other ledgers and VC formats, most notably the VC format W3C JSON-LD ZKP with BBS+ signatures. By Q1 2022, Aries offered full support for AnonCreds and W3C VC in JSON-LD ZKP using BBS+.\n",
    "* Multimessage signature schemes, such as CL (used in AnonCreds) and BBS+, is very different from the signatures schemes that the public sector is used to work with. Neither EBSI nor the Toolbox group is currently supporting it.\n",
    "* As of Q1 2022, efforts in Hyperledger Aries are shifting away from the W3C VC data model. The reason for this is practical (cf. the Q1 report [here](https://wiki.hyperledger.org/display/TSC/TSC+Project+Updates)). Many who want to deploy solutions quickly and test out VC and DLT, appreciate the full stack solution that is AnonCreds. To this end, work ins progressing on developing an [open specifications for the AnonCreds VC format](https://anoncreds-wg.github.io/anoncreds-spec/). \n",
    "* The Q2 2022 update reiterates that support for W3C standard VCs are still in progress and that developers wanting quick development should focus on AnonCreds.  \n",
    "\n",
    "Succinctly put: using Aries, Ursa, and Indy is very helpful if the main goal is learning about VC and how decentralized infrastructures like EBSI can support UCAD. Experiences from both Bolagsverket and from other enterprise focused UCAD projects have shown that AnonCreds is highly suitable for deploying solutions quickly. There is still a lot of development efforts ongoing with EBSI, and organizations would do well to keep up to date with recent developments. The assumption that underlies the text herein is that an organization can use Aries, Ursa, and Indy to get familiar with the core concepts, and thus be far more able to onboard EBSI once EBSI becomes mature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cf1232-08a3-4bb3-927c-d3f11102e98f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Disposition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c42d9a-9fc5-4000-9e85-80e947092956",
   "metadata": {},
   "source": [
    "This text will be structured as follows. First, the VC model is introduced both in general and with a specific focus on how the EBSI VC lifecycle looks like. The text aims to explain not only the model, but also the problem the model was introduced to solve. Common concepts and key terms will be described, followed by an introduction of the Trust Over IP (ToIP) stack. By the end of this first VC focused section, decision makers should be able to understand what VC and DLT enables and be ready to have a discussion with their IT colleagues on how to realize UCAD and how to leverage EBSI.\n",
    "\n",
    "Then, the text takes a technical deep dive into many core concepts required for developers to navigate VC and DLT in general, and EBSI VC specifically. In this section, the text describes each layer of the ToIP stack more in-depth. The text details also how Aries and Aries agents work and covers the major solution components of an UCAD ecosystem. Special attention will be given to help developers set up a test network for rapid development and quick deployment. Again, the focus is on enabling learning. This section will include also a description of EBSI conformant wallets and what EBSI services are usable today. This section will also explain major differences between Aries and the likely direction that EBSI is heading (e.g., with respect to revocation etc.).\n",
    "\n",
    "Finally, we focus on the controller component for UCAD. The controller is the organization specific codified business logic that provides an interface between the organization's existing systems and an UCAD ecosystem. This chapter will use ACA-Py and the Bolagsverket case as an exmaple.\n",
    "\n",
    "Throughout the text, there will be a strong emphasis on labs and active development and using code as a pedagogical tool for learning about VC and DLT."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434e72d6-a548-4b74-99cc-87e8e590e02c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Verifiable Credentials and their uses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb563975-86aa-4149-91b3-3aef48670222",
   "metadata": {},
   "source": [
    "*Note: Unless otherwise specified, the definitions for concepts used in this text are from here: https://www.w3.org/TR/vc-data-model/#terminology*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3640cf3-2d04-4ef0-82ce-cbab46427bab",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Credentials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc259265-84cd-46fa-bea9-922bc71c8782",
   "metadata": {},
   "source": [
    "The term credential has been defined in several ways, and the definition has evolved over time, which has lead to some degree of confusion. In [early work on VC](https://docs.google.com/document/d/1gfIz5TT0cNp2kxGMLFXr19x1uoZsruUe_0glHst2fZ8/edit#heading=h.jgdxyglhz3ik), the term credential was defined as \"a digital assertion containing a set of Claims made by an Entity about itself or another Entity\". These credentials were handled by different actors within a UCAD ecosystem, and the [Sovrin Glossary](https://docs.google.com/document/d/1gfIz5TT0cNp2kxGMLFXr19x1uoZsruUe_0glHst2fZ8/edit#heading=h.lyw4rdm1mutj) and the [W3C VC data model](https://www.w3.org/TR/vc-data-model/#ecosystem-overview)  both identify the following actors:\n",
    "\n",
    "* The entity described by the claims is the **credential subject**.\n",
    "* The entity creating the credential is the **credential issuer**.\n",
    "* The entity who controls and holds the credential is the **credential holder**.\n",
    "* The entity who uses Zero Knowledge Proofs to present a claim contained within a credential is called the **credential prover**.\n",
    "* The entity to whom the credential is presented is called a **Relying Party** or, if the credential is a VC, a **verifier**.\n",
    "\n",
    "In the context of the public sector, the [eIDAS legal framework](http://timspeelman.nl/eidas/#A3(52)) defines credential as \"a proof of a persons abilities, experience, right or permission\". The term in eIDAS that most closely resembles the Sovrin definition of a credential is 'electronic attestation of attributes' (EAA). The term [EAA](http://timspeelman.nl/eidas/#A3(44)) is defined as \"an attestation in electronic form that allows the authentication of attributes\" where an [attribute](http://timspeelman.nl/eidas/#A3(43)) is \"a feature, characteristic or quality of a natural or legal person or of an entity, in electronic form\". In this text we will not use the legal meaning of the word, but instead use credential and EAA interchangeably.\n",
    "\n",
    "There is also a distinction to be made between the credentials and verifiable credentials. Existing physical credentials, like a driver's license, contain information about \n",
    "\n",
    "* The type of the credential, i.e., driver's license.\n",
    "* The government authority that issued the credential.\n",
    "* The rights assigned to the identity subject of the driver's license (the credential subject and often holder).\n",
    "* Other claims about the credential holder\n",
    "* Information related to constraints on the credential, e.g., a validity period.\n",
    "\n",
    "When consuming services, the holder can show the driver's license to make assertions about claims like age, driving rights, or identity. Ideally, a credential contains information about the issuer and claims about the credential subject, and protects this information from being altered in some way. A VC shares many similarities with a physical credential, but also different in several important ways."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e197aefd-2468-49d3-94c0-f1d746395710",
   "metadata": {
    "tags": []
   },
   "source": [
    "## The VC data model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bc9bbe-cdf3-4924-85f4-2509fa88c249",
   "metadata": {},
   "source": [
    "A VC is similar to its physical counterpart insofar that:\n",
    "\n",
    "* An authorized issuer issues a VC containing claims about a credential subject.\n",
    "* The credential subject can hold the credential in their digital wallet.\n",
    "* A verifier can ask the holder to prove the claims from the credential.\n",
    "* The holder can generate a verifiable presentation, which includes information about the issuer and a proof that the shared claims are not forged.\n",
    "* The issuer can, if the credential supports it, also prove that the credential is still valid.\n",
    "\n",
    "Unlike their physical counterparts, a VC is cryptographically constructed, meaning that the evaluation of a credential is based solely on cryptography and not on the relying party's ability to spot a fake credential. The holder can use cryptography to generate a presentation that proves:\n",
    "\n",
    "* Who issued the credential.\n",
    "* That the credential was issued to the entity presenting it.\n",
    "* That the claims were not tampered with.\n",
    "* That the credential has not been revoked.\n",
    "\n",
    "One major advantage a VC has over a physical credential is that a VC can use cryptography to prevent 'oversharing' of data and thereby protect the privacy of the credential subjects. For instance, using a VC it is possible to derive an \"age over 18\" proof from the birth date, as opposed to disclosing the birth date in full. Using a VC, it is possible also to select specific claims to present, as opposed to having to show all of the claims. A core principle behind UCAD is that the credential subject / holder is in control of what data is shared and with whom.\n",
    "\n",
    "Above, the issuer, holder, and verifier were explained. There is one more important part of the VC ecosystem: The VDR. Most VC contain pointers to a VDR. The verifier can use a VDR to access information on the issuer and ensure they are an authorized source of the claims contained in the VC. The verifier can also use a VDR to access schemas and definitions, cryptographic material necessary to verify claims, and to perform validity status checks.\n",
    "\n",
    "<img src=\"https://www.w3.org/TR/vc-data-model/diagrams/ecosystem.svg\" alt=\"VC data model\" width=\"600\"/>\n",
    "\n",
    "**Fig 1**. *The Verifiable Credentials Data Model.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188d4c5f-fc85-44f3-9919-e0276c35c015",
   "metadata": {},
   "source": [
    "Above, the text has explained the various roles involved in a VC ecosystem and mentioned some of the properties of VC. Experiences show, however, that it is not always easy to know how to use these properties in real use cases and how the various roles interact. These topics are explored next."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed82bbbe-1d79-4cb3-9da6-981c4bb94c3b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## When to use VC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6930cdb-fafb-4ba6-a841-2b6b2182fe2f",
   "metadata": {},
   "source": [
    "On an aggregate level, use cases are comprised of needs, roles, tasks, and sequences. User needs define the problem space. The roles are the aforementioned issuer, holder, and verifier. The tasks define the functions that a users can accomplish using VC (e.g., selective disclosure of claims/attributes, generate proof of validity etc.). The sequences explain how a task is realized in interaction between the various actors involved. \n",
    "\n",
    "The W3C Use Case working group has identified a few illustrative needs that a user may have in different domains:\n",
    "\n",
    "<img src=\"https://www.w3.org/TR/vc-use-cases/VerifiableCredentialsProblemDomains.png\" alt=\"VC data model\" width=\"900\"/>\n",
    "\n",
    "**Fig 2**. Example of user needs in various domains.\n",
    "\n",
    "Each user need is further explained on the [W3C Use Case page](https://www.w3.org/TR/vc-use-cases/#user-needs). In this text, we will often illustrate concepts using education and legal identity. Therefore it is helpful to provide a short description of these two domains:\n",
    "\n",
    "* The *education* domain includes all levels of the educational experience; from primary through professional continuing education.\n",
    "* The *legal identity* domain includes cases where an entity must be able to prove some aspect of their identity in a way that can be quickly verified. Governments and other widely recognized entities are well positioned to provide such identification in a verifiable digital form.\n",
    "\n",
    "The use cases that are explored within EBSI will be detailed later in this text. To understand the detailed EBSI use cases, it is helpful to first understand a how to use VC, what a VC can look like, the involved flows, and how VC relates to verifiable presentations. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b8aed9-50ca-4bfa-817d-adad0c1f83b9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## How to use a VC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9b5a06-49e8-4eb5-bddb-5d1f5b208c52",
   "metadata": {},
   "source": [
    "Above, the user needs and the roles were discussed. Here, the text describes the tasks. These are important in order to understand the core principles behind VC.\n",
    "\n",
    "Core tasks include:\n",
    "\n",
    "1. **Issue a VC containing at least one claim**. Any entity must be able to issue a VC and include any claim. It is up to the verifier to assess the trustworthiness of a claim based on the issuer. For instance, a driver's license issued by the authorized agency has high trustworthiness. The same VC issued by the credential subject has low trustworthiness.\n",
    "2. **Assert a claim**. Most VC contain several claims.  The holder of a VC must be able to share exactly the information it intends with a verifier, and nothing else. The holder must also be able to limit the duration for the sharing of claims. \n",
    "3. **Verify a claim**. The verifier must be able to verify that the VC is an authentic statement of an issuer's claim about the subject. This requires the verifier to be able to:\n",
    "    * bind the holder to the presented claim(s), \n",
    "    * detect any tampering\n",
    "    * connect the VC to the issuer\n",
    "    * verify the authenticity of the VC\n",
    "4. **Store and manage claims**. The holder must be able to store the VC in a credential repository and the holder must be able to move credentials between credential repositories without requiring re-issuance.\n",
    "5. **Share claims**. The holder must be able to select what claims from what VCs to share with a verifier.\n",
    "6. **Revoke claim**. The issuer must be able to revoke a claim included in a VC.\n",
    "\n",
    "Perhaps the best way to illustrate the above tasks is to provide examples of a few scenarios that are difficult to achieve using existing credentials. These examples come from the [focal use case](https://www.w3.org/TR/vc-use-cases/#focal-use-cases) descriptions at the W3C use case working group.\n",
    "\n",
    "**Example 1. Claiming citizenship by parentage**\n",
    "\n",
    "Sam wants to claim US citizenship and his mother is American. Sam has a digital birth certificate from Kenya, where he was born. He also has his mother's digital US passport. His mother’s name changed between his birth and the issuance of the passport, so Sam also has a marriage license with her maiden and married names. Sam is applying for a new passport from the US Secretary of State.\n",
    "\n",
    "Sam can prepare the following VC set:\n",
    "\n",
    "* Birth certificate. Links Sam to his mother's maiden name.\n",
    "* Marriage license. Links the mother's maiden name with the present name.\n",
    "* Mother's passport. Establishes mother's US citizenship.\n",
    "* Sam's existing passport.\n",
    "\n",
    "Using the above VC set, Sam can prepare a verifiable presentation that selects claims from each of the above VCs and establishes that Sam is the credential subject (using e.g., a photo or other biometric data on his passport), that Sam is the child in the birth certificate, that the mother in the birth certificate is the same entity as the credential subject in the mother's passport VC and the marriage certificate.\n",
    "\n",
    "From a privacy perspective, it makes little sense to privacy preserve Sam's identity in this case since the claims he shares uniquely identify him. However, there are still some privacy aspects to consider. For instance, it should not be possible for the issuer of a VC to know that Sam is using the VC.\n",
    "\n",
    "**Example 2. Expert dive instruction**\n",
    "\n",
    "Pat earned multiple diving credentials while living and working in Fiji and Australia. Pat is now applying for a job as a NOAA Dive Instructor, which requires certification as an instructor with additional specialist diver certifications in dry suit, night diving, and search and recovery.\n",
    "\n",
    "Pat can prepare the following VC set:\n",
    "\n",
    "* Dive Instructor certification\n",
    "* Dry suit certification\n",
    "* Night diving certification\n",
    "* Search and recovery certification\n",
    "* Pat's existing legal identity credential\n",
    "\n",
    "Using the above VC set, Pat can prepare a verifiable presentation that establishes all the VC have the same credential subject and that he is that credential subject.\n",
    "\n",
    "**Example 3. International travel with minor and upgrade**\n",
    "\n",
    "Malathi is traveling internationally with her 8-month-old son, Anand. Malathi has enough frequent flyer miles to upgrade the ticket to first class.\n",
    "\n",
    "Malathi can prepare the following VC set:\n",
    "\n",
    "* Malathi's passport. Used in conjunction with the birth certificate.\n",
    "* Anand's passport. Used in conjunction with the birth certificate.\n",
    "* Anand's birth certificate. Used in conjunction with the passports.\n",
    "* Upgrade coupon. Used in conjunction with Malathi's passport.\n",
    "\n",
    "Malathi can now create a verifiable presentation that establishes that she is the mother of Anand and that she desires to use the upgrade coupon."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3896a2-f33b-40ab-a6eb-30bcdf6bc479",
   "metadata": {
    "tags": []
   },
   "source": [
    "## What a VC looks like"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c287f142-5ef7-463c-9496-b9b62683eb49",
   "metadata": {},
   "source": [
    "As mentioned, there are many types of VC formats. Below is a commented example of a W3C VC in JSON-LD (a more visual example will follow). The content mirrors Example 3. above, i.e., Malathi's passport.\n",
    "\n",
    "```JSON\n",
    "{\n",
    "  // set the context to provide information on the terms used\n",
    "  \"@context\": [\n",
    "    \"https://w3id.org/credentials/v1\",\n",
    "    \"https://example.com/travel-vocab/v1\"\n",
    "  ],\n",
    "  // specify the identifier of the VC\n",
    "  \"id\": \"urn:uuid:9f6878c8-73c7-11e8-ab37-23a1a3504fd0\",\n",
    "  // state the VC type, which declares what data to expect\n",
    "  \"type\": [\"VerifiableCredential\", \"PassportCredential\"],\n",
    "  // the issuer's identifier (DID) available on VDR \"example\"\n",
    "  \"issuer\": \"did:example:CCnF3zFaXkPN4zB94XaomRdvw2zX3XHPVX3aExcgo6PV\",\n",
    "  // some information about issuance, validity, and the subject\n",
    "  \"issuanceDate\": \"2010-01-01T19:23:24Z\",\n",
    "  \"expires\": \"2028-01-01T00:00:00Z\",\n",
    "  \"credentialSubject\": \"did:example:BcRisGnqV4QPb6bRmDCqEjyuubBarS1Y1nhDwxBMTXY4\",\n",
    "  // state the claims\n",
    "  \"claim\": {\n",
    "    // identifier of the credential subject, which is the same as above\n",
    "    \"id\": \"did:example:BcRisGnqV4QPb6bRmDCqEjyuubBarS1Y1nhDwxBMTXY4\",\n",
    "    \"passport\": {\n",
    "      \"id\": \"urn:uuid:79c181dc-73c7-11e8-8c1f-2bb1fd2d268a\",\n",
    "      \"type\": \"Passport\",\n",
    "      \"traveler\": {\n",
    "        // note that traveler is also credential subject\n",
    "        \"id\": \"did:example:BcRisGnqV4QPb6bRmDCqEjyuubBarS1Y1nhDwxBMTXY4\",\n",
    "        \"givenName\": \"Malathi\",\n",
    "        \"familyName\": \"Hamal\",\n",
    "        \"citizenship\": \"US\"\n",
    "      },\n",
    "      /* any other passport fields */\n",
    "    }\n",
    "  },\n",
    "  // validity information expressed below\n",
    "  \"credentialStatus\": {\n",
    "    \"id\": \"https://example.gov/status/24\",\n",
    "    \"type\": \"CredentialStatusList2010\"\n",
    "  },\n",
    "  \"proof\": {/* Signature by authorized issuer and associated metadata */}\n",
    "}\n",
    "```\n",
    "\n",
    "It is helpful to break down the example above into the core concepts used in the VC data model as defined by the W3C. At its core, the VC data model describes how claims can be made and how they are included in a VC. A claim is a statement about a subject expressed in a **subject-property-value** relationship. In the example above, there are several claims. For instance:\n",
    "\n",
    "* Malathi (subject) is a citizen of (property) the US (value).\n",
    "* The VC (subject) is of type (property) Verifiable Credential and Passport Credential (value).\n",
    "\n",
    "Every VC contains at least one claim. In addition, the VC contains also at least one proof and optional metadata. The metadata can describe the issuer, validity information (in the example above expressed as `credentialStatus`), verification related information (e.g., information on where to locate a verification key) etc. The proof is a signature over the claims part (and optionally the metadata part if present). The proof can be either included in the data object as a [Linked Data proof](https://www.w3.org/TR/vc-data-model/#data-integrity-proofs) or as a [JSON Web Token](https://www.w3.org/TR/vc-data-model/#json-web-token). For instance, consider the following illustrative graph of an example VC (note that this example is different from the JSON-LD example of Malathi's passport above).\n",
    "\n",
    "<img src=\"https://www.w3.org/TR/vc-data-model/diagrams/credential-graph.svg\" alt=\"Information graphs showing the basics of a VC\" width=\"700\">\n",
    "\n",
    "**Fig 3.** Information graphs showing the basics of a VC.\n",
    "\n",
    "In the graph, the VC identifier has the value `Credential 123`. This example VC is of type `AlumniCredential`, contains the issuer information `Example University`, and the issuance date, and a single claim; that Pat (subject) is an alumni of (property) Example University (value). Finally, the graph contains the proof part. The signature identifier is `Signature 456`. This example signature is of type `RsaSignature2018`, has the value specified in `signatureValue`, and contains a nonce together with information about how to verify it (using Example University public key 7).\n",
    "\n",
    "Note how a W3C JSON-LD VC is rather self contained. Not only does it contain pointers to information on how to interpret each term (in the `@context` section), it also provides all the required information to process all contained claims and to verify the entire VC. \n",
    "\n",
    "* Statements about specific things can be tagged with the optional `id` property so that interacting actors know they are expressing statements about the same things. \n",
    "* The mandatory `type` property lets software systems know whether or not the provided document is appropriate. \n",
    "* The mandatory `credentialSubject` property identifies the credential subject.\n",
    "* The mandatory `issuer` property identifies the issuer of the VC.\n",
    "\n",
    "As aforementioned, not all VC formats use JSON-LD. Some store context information outside the VC and rely on regular JSON. Others include linked data, but use another logic to structure the data and format it (e.g., the ISO/IEC 18013-5 mdoc format uses CBOR). This text is not focused specifically on JSON-LD. Interested readers should read the section on [basic concepts](https://www.w3.org/TR/vc-data-model/#basic-concepts) in the W3C VC data model page for additional details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe1f227-5f87-4f35-b0c7-9d262b1c7af8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## The flows involved in issuing and using a VC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316f5dac-3fda-4462-890c-5a93bd752402",
   "metadata": {},
   "source": [
    "Below are two sequence diagrams. The first illustrates an example credential issuance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a42d88-0c61-4da2-98c6-4a885fdd2305",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install IPlantUML\n",
    "import iplantuml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaffbb2-ce92-4cfc-8668-6b7a7cdae948",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%plantuml\n",
    "\n",
    "@startuml\n",
    "actor Alice as Al\n",
    "collections Agents as Ag\n",
    "database \"VC repository\" as S\n",
    "entity Issuer as I\n",
    "Al -> Ag: 1. Navigate to connection resource\n",
    "Ag <-> I: 2. Establish connection\n",
    "Al -> Ag: 3. Input VC choice\n",
    "Ag -> I: 4. Request credential\n",
    "I -> I: 5. Verify eligibility and create VC\n",
    "I -> Ag: 6. Send VC response\n",
    "Ag -> Al: 7. Display VC\n",
    "Al -> Ag: 8. Save VC\n",
    "Ag -> S: 9. Move VC to storage\n",
    "@enduml "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b6ccb2-3ad7-45b3-8792-10806f8b1b0c",
   "metadata": {},
   "source": [
    "Expanding on the above steps:\n",
    "\n",
    "1. Alice navigates to a resource where the issuer has provided connection information.\n",
    "2. Alice's edge agent (assuming she uses her smart phone) uses the connection information to establish a secure connection between itself and the issuer.\n",
    "3. Alice selects the VC she wants to receive.\n",
    "4. Alice's agents (oftentimes an edge agent works together with a cloud agent) creates a VC request and sends this secure to the issuer\n",
    "5. The issuer verifies Alice's eligibility for the VC and (assuming Alice is eligable) creates the VC\n",
    "6. The issuer sends the VC to Alice's cloud agent\n",
    "7. Alice's agents show the VC to Alice\n",
    "8. Alice selects save VC\n",
    "9. Alice's agents move the VC to the VC repository\n",
    "\n",
    "Next, we look at VC usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1147dc-597f-424e-952e-46f9af3b881d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%plantuml\n",
    "\n",
    "@startuml\n",
    "actor Alice as Al\n",
    "collections Agents as Ag\n",
    "database \"VC repository\" as S\n",
    "entity Verifier as V\n",
    "Al -> Ag: 1. Navigate to connection resource\n",
    "Ag <-> V: 2. Establish connection\n",
    "V -> Ag: 3. Request proof of age\n",
    "note left\n",
    "    The verifier provides \n",
    "    services to customers \n",
    "    above 18 years of age.\n",
    "end note\n",
    "Ag <-> S: 4. Collect list of available VC\n",
    "Ag -> Al: 5. Display list of relevant VC\n",
    "Al -> Ag: 6. Confirm intent to share and select VC\n",
    "Ag -> Ag: 7. Use VC to create verifiable\\npresentation with age ≥ 18 proof\n",
    "Ag -> V: 8. Send verifiable presentation\n",
    "V -> V: 9. Verify\n",
    "V -> Ag: Redirect\n",
    "@enduml "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11dcbb5c-0498-4b5e-b4d1-a1c50b89fa43",
   "metadata": {},
   "source": [
    "Expanding on the above steps:\n",
    "\n",
    "1. Alice navigates to a resource where the issuer has provided connection information.\n",
    "2. Alice's edge agent (assuming she uses her smart phone) uses the connection information to establish a secure connection between itself and the verifier.\n",
    "3. The verifier requests a proof of age to\n",
    "4. Alice's agents work with the VC repository to create a list of possible VCs Alice can use to satisfy the verifier's request\n",
    "5. Alice's agents work together to display this list to Alice\n",
    "6. Alice confirms the intent to share the claim and selects the VC to use\n",
    "7. Alice's agent(s) use the VC(s) to create a verifiable presentation with a proof that alice is above 18\n",
    "8. Alice's edge agent sends to verifiable presentation to the verifier\n",
    "9. The verifier verifies the claim\n",
    "10. The verifier sends a redirect to Alice's device.\n",
    "\n",
    "Note that both sequence diagrams included the term 'verifiable presentation'. This term will be explored next."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2be903-d03a-44b5-9f74-231eb67d4790",
   "metadata": {
    "tags": []
   },
   "source": [
    "## What a Verifiable Presentations is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f985220a-2879-4a4e-90ef-c62da84d0629",
   "metadata": {},
   "source": [
    "A VC is not the same as a verifiable presentation. And it is often not enough for a verifier to simply receive a VC. Some reasons for this include:\n",
    "\n",
    "* Verifiers need assurances that the credential holder actually intended to share the claims contained in the VC.\n",
    "* A VC may contain more information than what the user intended to share.\n",
    "* In the examples provided above, the holder often needed to link together difference VCs. But a VC does not include a proof of holder binding between claims shared from multiple different VC.\n",
    "* A holder may want to specify terms of use for the claims shared.\n",
    "\n",
    "Consequently, a verifiable presentation may be used to combine and present VC data. The data in a presentation may be about the same credential subject, but it is possible to create presentations involving multiple credential subjects (for instance, the example flow above with Claiming citizenship by parentage involved a verifiable presentation with two credential subjects, the applicant and the mother of said application).\n",
    "\n",
    "Below is an illustrative information graph for a verifiable presentation. Note how this graph builds on the previous example of a VC.\n",
    "\n",
    "<img src=\"https://www.w3.org/TR/vc-data-model/diagrams/presentation-graph.svg\" alt=\"Information graph showing the basics of a verifiable presentation\" width=\"700\">\n",
    "\n",
    "**Fig 4**. Information graphs showing the basics of a verifiable presentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9085f35b-867f-41b2-8e0d-a940e05085ab",
   "metadata": {
    "tags": []
   },
   "source": [
    "## The VC lifecycle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56af0a9-653c-4955-91e7-31012b25e7a9",
   "metadata": {},
   "source": [
    "The VC lifecycle depends on the implementation and the VC format. This section will first describe the generic steps involved, before focusing on how the VC lifecycle looks like in EBSI. In general, the VC lifecycle consists of:\n",
    "\n",
    "1. The issuer can issue each VC exactly once to the holder.\n",
    "2. The holder can:\n",
    "    1. delete each VC exactly once.\n",
    "    2. transfer a given VC any number of times\n",
    "    3. present claims from a VC any number of times\n",
    "3. The verifier can perform a validity status check on the VC any number of times. \n",
    "\n",
    "The issuer and the holder activities are rather straight forward. However, the specifics of how to perform a validity status check is ecosystem specific. Some, like eIDAS are encouraging privacy preserving options and flows where validity status checks are performed without the issuer being notified about the use of the VC. \n",
    "\n",
    "In EBSI the generic VC lifecycle is based on the W3C specifications, but is purpose fit. Before describing the [EBSI VC lifecycle](https://ec.europa.eu/digital-building-blocks/wikis/display/EBSIDOC/Verifiable+Credentials+Lifecycle), it is necessary to know that EBSI defines a fourth role in addition to the regular roles (i.e., issuers, holders, and verifiers). The EBSI VC ecosystem also includes the Trusted Accreditation Issuer (TAI). The TAI accredits the issuers to issue an EBSI VC. The reliance of a TAI means that, while anyone could issue a VC, only those issuers accredited by a TAI will be able to issue EBSI VC. As aforementioned, verifiers are tasked with assessing whether or not to trust a VC, and doing a check on the issuer is a key part of a verifier's assessment. For a VC to be consider an EBSI VC, it needs to issued by a TAI accredited issuer.\n",
    "\n",
    "For the EBSI VC to work, a TAI needs to:\n",
    "\n",
    "* register a self generated DID and the cryptographic material required for connection establishment and credential verification on a VDR that EBSI supports.\n",
    "* establish a trust model for their domain. \n",
    "* define schemas and manage these schemas using the Trusted Schemas Registry.\n",
    "* issue Verifiable Accreditations to Accreditation issuers and VC issuers.\n",
    "\n",
    "For the EBSI VC to work, a TAI accredited trusted issuer needs to:\n",
    "\n",
    "* obtain Verifiable Accreditations from TAI\n",
    "* register a self generated DID and the cryptographic material required for connection establishment and credential verification on a VDR that EBSI supports.\n",
    "* register and manage their Verifiable Accreditations to the EBSI Trusted Issuers Registry.\n",
    "* issue VC to holders\n",
    "* E-seal VC\n",
    "\n",
    "For the EBSI VC to work, a holder needs to:\n",
    "\n",
    "* generate DIDs and cryptographic keys in their wallets.\n",
    "* identify trusted issuers using the EBSI Trusted Issuers Registry.\n",
    "* request EBSI VC from TAI accredited trusted issuers.\n",
    "* share their EBSI VC with verifiers using verifiable presentations.\n",
    "\n",
    "Finally, verifiers can:\n",
    "\n",
    "* request EBSI VC from holders\n",
    "* verify the verifiable presentation and the claims contained within.\n",
    "* verify issuers and their accreditation status.\n",
    "\n",
    "Note how the steps include the generic issuer holder verifier interactions, but that the specific way trust is established is purpose fit for the context that EBSI was designed for. Note specifically how the EBSI ecosystem limits EBSI VC issuance to TAI accredited entities. This gives verifiers in the EBSI ecosystem a way to assess whether or not to trust an EBSI VC.\n",
    "\n",
    "Later in this text, we will do a technical deep dive into how EBSI works."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df38782-9df9-4b20-bca8-6bbc3146e0f1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## EBSI VC use cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd2d191-fa58-4350-a89a-37c7e882f4c4",
   "metadata": {},
   "source": [
    "Above, the text has described the following:\n",
    "\n",
    "* the VC data model, \n",
    "* when and how to use a VC, \n",
    "* the VC ecosystem components and participants and their interactions, \n",
    "* what a VC can look like, \n",
    "* the generic VC lifecycle, and \n",
    "* the EBSI VC specific adaptations. \n",
    "\n",
    "It is now suitable to introduce the various EBSI VC use cases. On the EBSI confluence page, there are currently 7 use cases described. These are: 1) the European Self-Sovereign Identity Framework (ESSIF), 2) Diplomas, 3) Document traceability, 4) Asylum process management, 5) European Social Security Pass (ESSP), 6) SME financing, and 7) Trusted data sharing. In addition, there are other use cases that have applied for formal EBSI use case status. These use cases are: unique building identity, compliance, vehicle management, supply chain visibility, immunization, trust networks for SME, immigration control, health insurance cards, markets for media assets, public procurement, debt and equity financing, project service infrastructure, driving license, fraud prevention, eHealth, sustainable cities, and tourism. A few of the proposed use cases will be described next, followed by a more in depth description of some specific adopted EBSI use cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8063c1c5-4b1a-43bc-aa9a-69627547c0e9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Examples of proposed EBSI use cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c183b625-7cc0-42f7-8494-144ca941fbe0",
   "metadata": {
    "tags": []
   },
   "source": [
    "The following are the proposed use cases for EBSI that have so far not been adopted. The described use cases are selected based on the order they appeared on the EBSI application page (and as such were not handpicked to make a point). Together, the three are representative of a broader theme in all applications, i.e., using EBSI for either identity or as a coordination tool for enabling trusted data exchanges in complex and dynamic networks.\n",
    "\n",
    "#### Unique Building Identification\n",
    "\n",
    "**The use case in brief**:  Develop a Unique Building Identification (UBI) and use if as the backbone of an information infrastructure where monitoring and construction data is shared between stakeholders.\n",
    "**Claimed benefit with EBSI**: Building monitoring data and construction data comes from a wide range of sources and from different countries. These data need to be pooled together for further analysis. But analysis is not possible if the data is not trustworthy. The use of EBSI VC to establish UBI is a way to establish trust.\n",
    "\n",
    "#### Compliance by design\n",
    "\n",
    "**The use case in brief**: Develop a system in which (financial) processes can be executed in a way that is always completely compliant with all applicable laws and regulations. Three main functions: 1) compliance through enforcement of laws and regulations, 2) simplify accountability by performing audits ex ante, and 3) combine and analyze information to allow traceability of public funds.\n",
    "**Claimed benefit with EBSI**: The use case is not VC related but proposes using Ethereum smart contracts on the Hyperledger Besu network that runs on EBSI.\n",
    "\n",
    "#### Management of a vehicle's lifecycle\n",
    "\n",
    "**The use case in brief**: To gather all relevant information along the lifecycle of a car across organizations and states and to establish a way to generate a transparent, trustworthy, and verified vehicle history report. To do so, the use case describes a need for secure and reliable data exchanges with customizable data ownership. A key enabler for all is to have a way to establish unique identities for entities (vehicles, parts, data etc.).\n",
    "**Claimed benefit with EBSI**: The use of an EBSI DLT (more specifically [R3 Corda](https://www.corda.net/)) to register information on identities. However, EBSI does not support Corda or its specific way to handle and manage identity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edff0c76-6484-4537-b856-da11ca6ea74b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### ESSIF as an example of an adopted EBSI use cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2b06ac-1046-4ef0-b252-3c1b37adfdca",
   "metadata": {},
   "source": [
    "Arguably, the ESSIF use case is the most developed one out of the seven adopted use cases in EBSI. In addition to ESSIF, the diplomas use case is advanced too. However, the diplomas use case builds extensively on the following three components: \n",
    "\n",
    "1. The W3C VC data model, \n",
    "2. The ESSIF natural and legal person DIDs and ESSIF compliant proofs, and \n",
    "3. The Europass data model for educational credentials (ESSIF's scope does not include data models and schemas).\n",
    "\n",
    "The diplomas use case details several user flows and other user journeys, and the material is quite developed. However, the focus of the text herein is on the technology and thus the specific user flow is outside the scope of this text. Therefore, this text will focus on describing ESSIF as the W3C VC data model has already been explored. In essence, if a reader understands the W3C VC data model, the identity ideas that inspire ESSIF, and has a look at the Europass data model for educational credentials, then it is trivial to understand the technical parts of the diplomas use case.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4068c406-e164-4f0a-885c-16d98ab7f866",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### The European Self Sovereign Identity Framework\n",
    "\n",
    "The ESSIF use case is influenced by two main streams of though: 1) Self Sovereign Identity (SSI), and 2) the W3C VC model. \n",
    "\n",
    "The SSI concept is ill defined and highly politicized and the [wikipedia page on SSI](https://en.wikipedia.org/wiki/Self-sovereign_identity) and the references provided therein is probably the best start for a reader interested in the topic. On a high level, SSI is the idea that an identity subject control their own data and when and how it is provided to others. With SSI, there is no central authority holding data that passes it on to others upon request/consent. The data subject is in total and complete control of their own data. And because of the underlying cryptography and the decentralized nature of the supporting infrastructures, SSI enables claims presentations that others can verify with cryptographic certainty. Readers interested in learning how ESSIF builds on SSI are referred to the ESSIF text \"[How we use SSI](https://ec.europa.eu/digital-building-blocks/wikis/display/EBSIDOC/%5Barchived%5DESSIF+How+we+use+SSI)\".\n",
    "\n",
    "The ESSIF use case in brief:\n",
    "\n",
    "* it is about \"implementing a generic SSI capability, allowing users to create and control their own identity without relying on centralized authorities.\" The use case become an EBSI use case to address challenges related to digital identity in a cross border setting.\n",
    "* wants to leverage SSI principles (arguably, UCAD exchanges are a core feature in SSI) as an alternative to today's data management in the public sector where natural persons and legal persons cannot access their own data easily as these data are often tightly controlled and protected by centralized public authorities.\n",
    "* wants to establish a framework under which different compliant SSI solutions and services can be recognized.\n",
    "* address some of the challenges in the existing solutions for the Once Only Principle (OOP), where cross border exchanges of data can be fairly complex and where the data subject is not in absolute control over these data flows (OOP is consent based).\n",
    "* GDPR compliance is important and ESSIF wants to enable a user centric way to manage consent information. Here, the [Automated Data Agreements project](https://github.com/decentralised-dataexchange/automated-data-agreements) is especially noteworthy as it enables using any VC ecosystem to manage a user's consent using VC.\n",
    "* the problems ESSIF wants to solve are as follows:\n",
    "    * Data acquisition and maintenance\n",
    "    * Data processing and the lack of identity enhanced data exchanges (i.e., it is often hard to know the source of data)\n",
    "    * Breaking down data silos\n",
    "    * Data subjects are not in control over their own identity data\n",
    "    * Existing solutions are not privacy preserving\n",
    "    * Today's solutions are not universal, linkable, or interoperable\n",
    "    * Citizens may have multiple national identities and it is hard identity in Europe.\n",
    "    * Lack of certifications\n",
    "\n",
    "To the above, the scope of ESSIF is to facilitate cross-border interactions using SSI and to enable UCAD within Europe. To do so, ESSIF is engaged in building an identity layer for EBSI. The technology of choice is the aforementioned adaptation of W3C VC and verifiable presentations and the ESSIF functional schematic is very similar to the VC data model shown above in Figure 1. A TAI accredited issuer can issue EBSI VC directly to holders, or issue EBSI VC following a credential request by the holder. The holder uses a personal data repository to store EBSI VC and the cryptographic secrets required for establishing secure communications channels and for signing an EBSI VC into an EBSI verifiable presentation. The verifier can request a verifiable presentation or the holder can create a verifiable presentation and send one to the verifier without a prior request. Relatedly, the roles and tasks are similar too, as are the described flows (for more details see the [ESSIF functional specifications](https://ec.europa.eu/digital-building-blocks/wikis/display/EBSIDOC/%5Barchived%5DESSIF+Functional+Specifications)).\n",
    "\n",
    "As ESSIF builds extensively on W3C VC (and other related technologies considered core for SSI like Decentralized Identifiers), it is not worth describing the roles and flows in additional detail. Instead, consider the following example of an ESSIF VC:\n",
    "\n",
    "```JSON\n",
    "{\n",
    "  \"@context\": [\n",
    "    \"https://www.w3.org/2018/credentials/v1\",\n",
    "    \"https://essif.europa.eu/schemas/vc/2019/v1\",\n",
    "    \"https://essif.europa.eu/schemas/eidas/2019/v1\"],\n",
    "  \"id\": \"did:ebsi-eth:00000001/credentials/1872\",\n",
    "  \"type\": [\"VerifiableCredential\", \"EssifVerifiableID\"],\n",
    "  \"issuer\": \"did:ebsi-eth:00000001\",\n",
    "  \"issuanceDate\": \"2019-06-22T14:11:44Z\",\n",
    "  \"credentialSubject\": {\n",
    "    \"id\": \"did:ebsi-eth:00000002\",\n",
    "    \"currentFamilyName\": \"Franz\",\n",
    "    \"currentGivenName\": \"Hinterberger\",\n",
    "    \"dateOfBirth\": \"1999-03-22T00:00:00Z\",\n",
    "    \"placeOfBirth\": \"Salzburg, Austria\"\n",
    "  },\n",
    "  \"proof\": [ {\n",
    "    \"type\": \"EcdsaSecp256k1Signature2019\",\n",
    "    \"created\": \"2019-06-22T14:11:44Z\",\n",
    "    \"proofPurpose\": \"assertionMethod\",\n",
    "    \"verificationMethod\": \"did:ebsi-eth:00000001#key-1\",\n",
    "    \"jws\": \"eyJhbGciOiJSUzI1Ni..TCYt5X\"\n",
    "  },\n",
    "            {\n",
    "    \"type\": \"EidasSeal2019\",\n",
    "    \"created\": \"2019-06-22T14:11:44Z\",\n",
    "    \"proofPurpose\": \"assertionMethod\",\n",
    "    \"verificationMethod\": {\n",
    "      \"type\": \"EidasCertificate2019\",\n",
    "      \"CertSerial\": \"1088321447\"\n",
    "    },\n",
    "    \"proofValue\": \"BD21J4fdlnBvBA+y6D...fnC8Y=\"\n",
    "  } ]\n",
    "}\n",
    "```\n",
    "\n",
    "What is interesting, however, is the VDR that ESSIF proposes and the specifics of this VDR. Since EBSI is blockchain agnostic (this means that EBSI is not a blockchain, but an infrastructure that can host a number of different decentralized/distributed storage solutions including blockchains and DLTs), ESSIF requires that EBSI can support multiple different VDR solutions. Or as ESSIF explains:\n",
    "\n",
    "> In the SSI stack, DLTs are typically the base, with other infrastructure layers above such as abstraction layers associated with identifiers, protocols and claims, before reaching the application layers. This being said, DLT layers are not necessarily more influential as everything should be DLT agnostic. \n",
    "\n",
    "The ESSIF use case aims to use DLTs for two main purposes:\n",
    "\n",
    "1. to register DID documents on a ledger (for more information on DID documents and DIDs, see the Trust over IP stack section in this text).\n",
    "2. to register metadata of EBSI VC including validity status related objects (e.g., certificate revocation lists).\n",
    "\n",
    "There is also a discussion around hosting trusted issuer lists on an EBSI DLT, but work there is not yet complete."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce72826-bc16-496d-80a2-76f88bcc0d97",
   "metadata": {
    "tags": []
   },
   "source": [
    "# A technical deep dive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae837e9-a329-45f5-8ac3-d23a414ae58e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## The Trust over IP stack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1785868-763c-481b-9cd5-390199e7ff13",
   "metadata": {},
   "source": [
    "A common term mentioned with regards to VC and UCAD is [Trust over IP](https://trustoverip.org/) (ToIP). As a Linux Foundation organization, the ToIP is working on defining a complete architecture for Internet-scale digital trust that combines both cryptographic trust at the machine layer and human trust at the business, legal and social layers. Its dual focus is achieved through two tracks: Technology and Governance. The technology stack contains all the technical components that make it possible to exchange verifiable UCAD between two actors. The technical capabilities embodied in Indy, Aries and Ursa enable this capability at the machine layer. As ToIP covers identity, it is often referred to in SSI dialogues. But ToIP is more than just identity, and it goes beyond allowing an identity subject to share attributes about itself to cover any type of authentic data. \n",
    "\n",
    "The governance track runs in parallel and contains the rules and policies that govern each layer of the technical solution. It is at this layer where the policy decisions regarding the technical components are made. For instance, the W3C VC model requires a VDR. Technically, there are many options, but policy makers must decide on which VDR to pick, who is allowed to author / endorse transactions to that VDR, how to maintain and manage the infrastructure etc.\n",
    "\n",
    "<img src = \"https://camo.githubusercontent.com/75580772e2f4e79d179050a26ab57260c4cba72dab60834860571629a5764718/68747470733a2f2f6d69726f2e6d656469756d2e636f6d2f6d61782f313430302f312a44675042706e545f527844456e645f707464796e6b512e706e67\" alt=\"The ToIP dual stack model.\" width = 700>\n",
    "\n",
    "**Fig 5.** The dual stack ToIP ([source](https://www.dizme.io/)).\n",
    "\n",
    "At each layer, the technology and the governance stack define the technical components and the information that governs these components. Technology focused staff and policy focused staff must decide, together, on the components of each layer. Oftentimes, the technologists are faced with a multitude of different options that are mutually exclusive and that require a selection between certain parameters to optimize for. It is the role of technologists in a dialogue to clearly explain these parameters and the implications of various choices. In turn, policy makers need to translate the public will into an answer to what parameters to optimize for. The first three layers are of interest herein, and merit additional explanation:\n",
    "\n",
    "* At layer 1, where cryptographic trust is anchored, governance defines what VDR to use, who is allowed to register an entity, who can create and commit transactions to trigger state changes, how to publish and find information necessary for enabling the higher layers etc. Using EBSI as an example, the VDR choice contains multiple storage solutions and also includes Hyperledger Fabric and Hyperleder Besu as two DLT based VDRs. In Sweden, the Swedish development node also supports the [Interplanetary File System](https://ipfs.io/) (IPFS). In EBSI, the read and write access depends on the storage solution and everything is carefully governed to establish a high degree of trust that is fit for the purpose of a public sector services infrastructure.\n",
    "* At layer 2, where connections are established between entities, governance selects the form factor to focus on and the extent to which to rely on existing standards and ways of working *vis-á-vis* more novel ways that may be less familiar but more feature rich. Using EBSI as an example, it supports multiple different solutions. A choice that is increasingly popular, and that is being discussed in both EBSI and at the Toolbox group, is using OpenID Connect with [SIOPv2](https://openid.net/specs/openid-connect-self-issued-v2-1_0.html).\n",
    "* At layer 3, where VC are exchanged, governance defines how a verifier can trust the issuer of a credential. Governance also defines how to determine what the information in the credential means and under whose authority and using what processes did the issuer issue the VC. In EBSI, it would be possible to rely on [OPID4VC](https://openid.net/2022/05/12/openid-for-verifiable-credentials-whitepaper/) in order to exchange any verifiable credential format, including W3C VC. Relatedly, a holder could then present a a VC using [OIDC4VP](https://openid.net/specs/openid-4-verifiable-presentations-1_0.html). Also, EBSI is adopting the W3C VC format, but has context specific governance rules for who can be an issuer (i.e., must be TAI accredited).\n",
    "\n",
    "To exemplify the above, Aries implements DIDComm for sending messages based on DIDs (decentralized identifiers). Hyperledger Indy provides both a Layer 1 DID utility mechanism and Layer 3 verifiable credential format called [AnonCreds](https://anoncreds-wg.github.io/anoncreds-spec/). Aries works with Indy and with other layer 1 VDRs and supports the W3C Standard VC format. In the Toolbox work, OPIDC is being discussed for message exchanges, the VDR is optional and use case specific, and there is a much more extended discussion on formats to support."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afa4c7b-d6e8-4767-8b6f-e72a446d5a41",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Decentralized Identifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365ea29b-02d8-46f2-b34b-f9b6260ef2bc",
   "metadata": {},
   "source": [
    "A [decentralized identifier](https://w3c.github.io/did-core/) (DID), is a universally unique identifier (uuid) that is associated with a cryptographic key. There are two types of DIDs to consider:\n",
    "\n",
    "1. Public DIDs. A public DID is published and can be used by anyone. \n",
    "2. Pairwise DIDs. Are similar to public DIDs, but are not published. Pairwise DIDs are established between two entities only and are relationship specific.\n",
    "\n",
    "A DID resolves into a DID Document, which contains all the information required to create a connection to the DID controller.\n",
    "\n",
    "<img src = 'fig/did.svg' width = 400>\n",
    "\n",
    "The standard elements of a DID Document include (or can include):\n",
    "\n",
    "1. The DID itself as the document identifier\n",
    "2. A set of public keys \n",
    "3. A set of authentication methods\n",
    "4. A set of service endpoints for interaction\n",
    "5. A timestamp to enable audits\n",
    "6. A signature to ensure integrity\n",
    "\n",
    "To enable trust in the identity ecosystem, certain actors register their DID on a public data registry. Note that the properties of the data registry determines the technical trust in the DID registration. For instance, actors may wish to use publicly verifiable hash pointers for retrieval. An Aries agent will publish an issuer’s public DID on a DLT. This would allow a holder to find information about the issuer's verkey and a physical endpoint  to which messages can be sent to the agent.\n",
    "\n",
    "<img src = 'fig/diddoc.svg' width = 600>\n",
    "\n",
    "The DID method is a specification for how to create, update, delete a DID Document. Each VDR has a specific DID method, some have several. To learn about the DID method for a specific VDR, see the [W3C did spec registry](https://w3c.github.io/did-spec-registries/#did-methods).\n",
    "\n",
    "A DID can look like this: \n",
    "\n",
    "<img src = \"https://w3c.github.io/did-core/diagrams/parts-of-a-did.svg\" alt = \"Example of DID\" width = \"300\">\n",
    "\n",
    "And and example of a DID document that is resolved by a DID looks like this:\n",
    "\n",
    "```JSON\n",
    "{\n",
    "  \"@context\": [\n",
    "    \"https://www.w3.org/ns/did/v1\",\n",
    "    \"https://w3id.org/security/suites/ed25519-2020/v1\"\n",
    "  ]\n",
    "  \"id\": \"did:example:123456789abcdefghi\",\n",
    "  \"authentication\": [{\n",
    "    \n",
    "    \"id\": \"did:example:123456789abcdefghi#keys-1\",\n",
    "    \"type\": \"Ed25519VerificationKey2020\",\n",
    "    \"controller\": \"did:example:123456789abcdefghi\",\n",
    "    \"publicKeyMultibase\": \"zH3C2AVvLMv6gmMNam3uVAjZpfkcJCwDwnZn6z3wXmqPV\"\n",
    "  }]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2b2c11-d0d2-4158-8b9e-d6944e406285",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Formats for VCs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb755640-c158-458b-b5bd-eb506a60808a",
   "metadata": {},
   "source": [
    "There are many different VC formats. A few noteworthy VC formats include AnonCreds, the ISO/IEC 18013-5 mdoc / MSO, JWT presentation profile, SD-JWT, ICAO DTC, W3C JSON-LD. An extensive review of these formats is available [here](https://docs.google.com/spreadsheets/d/1yrolklYsvzsUn1xvKJWO_DGpjcNnZa0N2DTAnbW3t6I/edit?usp=sharing) and a more high level overview is provided [here](https://www.lfph.io/wp-content/uploads/2021/04/Verifiable-Credentials-Flavors-Explained-Infographic.pdf) and [here](https://www.lfph.io/wp-content/uploads/2021/02/Verifiable-Credentials-Flavors-Explained.pdf).\n",
    "\n",
    "Each VC format should specify the following: \n",
    "\n",
    "1. the credential format itself \n",
    "2. the proof mechanism \n",
    "3. how validity status checks are handled\n",
    "4. the key management approach\n",
    "\n",
    "In addition to assessing each point individually, it is important to assess the interactions between them. For instance, if the credential format does not support a privacy preserving proof mechanism, then the two cannot be used together. Similarly, if the format and the proof mechanism is privacy preserving, but the validity status check is not, then there is an inconsistency that needs to be addressed. And everything can be privacy preserving, but if the VC format is bound to a device using a unique device ID with an X.509, then privacy is lost everytime this identifier is shared. A brief discussion on what to consider when searching for suitable combinations follows next.\n",
    "\n",
    "### Finding suitable combinations \n",
    "\n",
    "It can be overwhelming to narrow down the choices for the possible combinations that exist. To narrow down the options, a key consideration is the features that the VC should support. Here is a list of what is commonly considered:\n",
    "\n",
    "1. Selective disclosure capabilities. Selective disclosure is the ability to present multi show unlinkable subsets of the claims a holder has.\n",
    "2. Standardization efforts and status.\n",
    "3. Implementation support and complexity.\n",
    "4. Technology readiness. Public sector actors will only support well tested formats, proof mechanisms, key management approaches etc.\n",
    "5. Support for cryptographic agility. \n",
    "6. Support for predicate proofs.\n",
    "7. Support for rich schemas and semantic embedding.\n",
    "8. The possibility to rely on common hardware backed implementations for signatures\n",
    "9. The possibility to blind a signature\n",
    "10. The level of information the validity status check leaks to a verifier.\n",
    "11. The degree to which the issuer can use the validity status check to track the holder.\n",
    "12. The scalability of the validity status check approach.\n",
    "13. The way the identity subject is bound to the claims and the proof of these claims.\n",
    "14. The performance characteristics of all the points above.\n",
    "\n",
    "Each point deserves a text on its own. Herein, we will look specifically at a few of the above points. The choice of points was motivated by the educational needs of the Swedish Company Registration Offices, the ongoing work in the Common Union Toolbox group, and the work done at EBSI at the time of this writing. These points are presented in sections below in no particular order."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e1aa1c-e33b-46fd-b089-0b142606e249",
   "metadata": {},
   "source": [
    "#### Point 1: Zero Knowledge Proofs\n",
    "\n",
    "Zero Knowledge Proofs (ZKP) are often mentioned when discussing UCAD. However, ZKP is seldom explained, and often when it is explained then the explanation is either too difficult to understand or simply wrong. Therefore, the text herein will focus on an attempt to provide a better understanding of what ZKP is.\n",
    "\n",
    "When discussing ZKP, there are really two main discussion to be had. The first is focused on circuit design and is not something covered herein. The second is more high level and focused on the math and protocols. Within the second, the discussion depends on the particular way to realize ZKP and what properties the protocol has. It can be rather overwhelming. For those new to the concept, it is highly recommended to start with the following resources\n",
    "\n",
    "* Prof. Amit Sahai from UCLA: https://www.youtube.com/watch?v=fOGdb1CTu5c\n",
    "* Prof. Avi Wigderson from Princeton: https://www.youtube.com/watch?v=5ovdoxnfFVc\n",
    "\n",
    "In this text, the ZKP concept will be described a bit more in depth. To better understand the concepts discussed, it is helpful to read the Wiki entry on the [Fiat-Shamir heuristic](https://en.wikipedia.org/wiki/Fiat%E2%80%93Shamir_heuristic). In essence, a ZKP is a *property* of a proof system, and a part of that property is that only the knowledge of $x$ is revealed and absolutely nothing else. In fact, it should be possible to generate the entire interaction without knowing $x$ (this sentence is weird but can be understood using [an example with time machines](https://blog.cryptographyengineering.com/2014/11/27/zero-knowledge-proofs-illustrated-primer/)). In addition, a ZKP proof system must be complete (i.e., it should be possible to reveal knowledge of $x$ with a high degree of certainty) and it must be sound (i.e., it must be possible to extract $x$). The soundness property is especially important given that it is possible for an entity not knowing $x$ to generate an interaction indistinguishable from an entity that actually knows $x$. The above is rather abstract and perhaps best illustrated with a comparison with something known and then an example. \n",
    "\n",
    "Consider the example of a cryptographic hash function, $H()$, presents a way to generate a knowledge proof (note that ZKP is not the same as a knowledge proof). If $H()$ is [second preimage resistant](https://en.wikipedia.org/wiki/Preimage_attack) and has a large co-domain, then it can be used as a helpful tool to satisfy completeness as presenting $x$ will allow a verifier to check $H(x)$ and if a match is found the verifier can be certain that the prover knows the right $x$. However, $H(x)$ does not satisfy soundness as it is one way, i.e., it is not possible to extract $x$ from $H(x)$, and it is not Zero Knowledge since $H(x)$ reveals the digest of $x$.\n",
    "\n",
    "To understand a ZKP, consider the example:\n",
    "\n",
    "1. The prover publishes a commitment $h=g^x \\mod p$ and wants to prove knowledge of $x$\n",
    "2. The prover picks a random $r \\leftarrow R()$ and publishes $R = g^r$\n",
    "3. The verifier sends a random challenge $e \\leftarrow R()$. Alternatively, the verifier can source the random value from $H(g,h,R)$\n",
    "4. Prover sends $d=ex+r$. Since $r$ is random, $d$ is indistinguishable from random.\n",
    "5. Verifer checks that $h^e R = g^d$. Note how every element is indistinguishable from random.\n",
    "    * The proof works because $(g^x)^e g^r = g^{xe+r}=g^d$\n",
    "\n",
    "The above is complete and sound. But what about Zero Knowledge? Consider the following transcript generated by an entity that does not know $x$.\n",
    "\n",
    "1. Pick at random $(e,d) \\leftarrow R()$\n",
    "2. Set $R=\\frac{g^d}{h^e}$ and output $(R,e,d)$\n",
    "3. The above satisfies $h^e R = g^d$ without any knowledge of $x$\n",
    "\n",
    "The above illustrates why it is important that $x$ can be extracted. A proof system with the ZKP property must therefore have an *extractor*. This extractor can extract $x$ from the interaction if such an $x$ is known. Consider the following extractor for the interactions displayed above.\n",
    "\n",
    "1. Pick $R = g^r$\n",
    "2. Generate random challenge pair $(e_0,e_1) \\leftarrow R()$\n",
    "3. Generate $d_0 = e_0 x + r$ and $d_1 = e_1 x + r$\n",
    "4. Verify that $h^{e_0} R = g^{d_0}$, and $h^{e_1} R = g^{d_1}$\n",
    "5. Compute $g^{(d_0 - d_1) / (e_0 - e_1)} = g^{(e_0 x +r - e_1 x -r) / (e_0-e_1)}=g^x = h$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117fe37e-bfa9-4771-ab6e-b479752ce694",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Point 2: Validity status checks\n",
    "\n",
    "Some general requirements for validity status checks include the following assessment criteria:\n",
    "\n",
    "* Efficiency - The revocation approach should require minimal resources in terms of computation, bandwidth, and storage.\n",
    "* Timeliness - Revocation status updates should be sent frequently enough so that the validity status of a PID/(Q)EAA never becomes stale. Timeliness relates both to the efficiency of updating the revocation status object, and the distribution of the updated revocation information.\n",
    "* Privacy - The revocation approach should consider privacy. In particular:\n",
    "* Separation - A separation between the issuer and the validity status check service is strongly encouraged, in order to prevent issuers from learning about the use of issued attestations\n",
    "* Uncorrelatability - The PID/(Q)EAA should limit the possibility to correlate a holder's activities between verifiers, or across verifiers and issuers, beyond what is already possible on the basis of the shared attributes. This limitation includes e.g., metadata and signature data.\n",
    "* Data minimization - Accessing the validity status record should not reveal information about the holder, the entity who wants to learn the outcome of the validity status check, or the PID/(Q)EAA of interest.\n",
    "* Deployability - It should be easy to integrate and implement the revocation approach and there must exist incentives to do so. In addition, we should consider Member State interoperability, maturity, and the existence of open standards. Finally, we consider cryptographically more complex approaches harder to deploy as these do not necessarily build on existing competences and knowledge. \n",
    "\n",
    "An examination of current validity status approaches follows next.\n",
    "\n",
    "There are numerous ways to perform validity status checks in general. In essence, all of these ways are about proving that a particular element (e.g., a credential or a user) is a member, or not, of a set (e.g., a collection of valid\\revoked credentials or users). This can be done either implicitly, i.e., each VC is periodically re-issued or generated for a particular interaction, and is therefore assumed ‘fresh’. Implicit revocation does not, as above described, require the distribution of revocation information and will thus not be covered herein.\n",
    "\n",
    "Validity status checks such as revocation can also be done explicitly. Revoked VC are periodically announced and there is a need to distribute revocation information. Every explicit way represents a different tradeoff between various parameters and balancing these tradeoffs can be challenging.\n",
    "\n",
    "**Certificate revocation lists (CRLs)** are defined in internet standards RFC 6818 and 5280 and can be considered a mature and widely deployed technology for handling revocation. A CRL contains a signed list of identifiers for digital certificates that have been revoked by an issuing certificate authority (CA) before their scheduled expiration date and should no longer be trusted. A Validation Authority (VA) periodically posts this signed Certificate Revocation List (CRL) containing these certificate identifiers. Below we evaluate CRL with relation to each assessment criteria.\n",
    "\n",
    "Revocation lists typically incur performance problems because they can grow indefinitely. This burdens both the server and the client fetching the information. Mechanisms such as delta CRL, partial CRL, rotation of issuing CAs, or hybrid approaches where VC are time limited with relatively long durations (e.g., a driver’s license) can partly mitigate the performance problem, but these benefits come at the cost of increased complexity of deployments.\n",
    "\n",
    "It is worth also to mention that there exists revocation approaches using lists where the items in the list are selected based on some criteria. Google’s CRLsets and Mozilla’s OneCRL are both examples of this approach, where the focus is protection against critical certificate compromises and thus excludes validity information that is administrative in nature (e.g., expired).\n",
    "\n",
    "A CRL can achieve privacy providing more validity status information than is necessary (bundling is optional). When bundling is used, a specific user is ‘hidden’ among many others in a CRL. Consequently, third parties or eavesdroppers learn only a coarse grained access pattern. The three privacy requirements in relation to CRL:\n",
    "\n",
    "* Separation - It is possible to clearly separate the PID/(Q)EAA issuer from the validity status service provider. The issuer / validity service provider can only learn that the PID/(Q)EAA of interest is in a given set even when colluding.\n",
    "* Uncorrelatability - CRLs include unique PID/(Q)EAA identifiers and are thus easily correlatable. Thus, more user information is revealed with each validity status check.\n",
    "* Data minimization - Requesting a CRL can inform the CRL provider what credential set the holder/verifier is interested in (the requested set of identifiers will include the identifier of interest), which in turn reveals an intended use of the corresponding PID/(Q)EAA.\n",
    "\n",
    "Deployability is one major drawback with CRLs in a EUDIW ecosystem. The standard is designed for X.509 certificates only and may not be suitable for non-PKI based electronic attestation solutions or solution components (e.g., a DID).\n",
    "\n",
    "**The Online Certificate Status Protocol (OCSP)** is an Internet protocol used for obtaining the revocation status of X.509 digital certificates. The protocol is described in RFC 6960 and is on the Internet standards track; it is mature and widely deployed. It is often used in place of or as a supplement to CRLs.\n",
    "\n",
    "The main benefit with OCSP is that the revocation status will not be stale as it is supplied in near real time. There are, however, many drawbacks with OCSP: it was not designed with offline capabilities in mind, it can scale somewhat poorly (depends on deployment strategy) and may therefore not be suitable for the rapid increase in validity status checks that we can expect with the ecosystem, and the involved entities become dependent on the OCSP responder. There are also potential security concerns if soft fail implementations are permitted, i.e., when an entity may accept an “unknown” response and proceed without completing the validity status check.\n",
    "\n",
    "The main reason OCSP is not suitable for an UCAD ecosystem is related to privacy. The OCSP was not designed with privacy in mind and it cannot achieve privacy. The protocol shares the unique serial number of a VC with an OCSP responder, which checks revocation status of the certificate against a revocation database and returns a response (status 'good', 'revoked', or 'unknown'). So, from a privacy perspective, OCSP (and most approaches that rely on a third party agent, server, responder, distribution point etc.) risks revealing more information than the holder intended. The three privacy requirements with relation to OCSP:\n",
    "\n",
    "* Separation - The issuer and the responder can be different entities but unless the CA database is accessed by the OCSP responder in a private way, there is no separation.\n",
    "* Uncorrelatability - An OCSP request includes a unique identifier. It is trivial to correlate the user’s activities both between OCSP requests to the same OCSP responder, and between any colluding actors who learn the unique identifier.\n",
    "* Data minimization - An OCSP reveals to the OCSP responder exactly what PID/(Q)EAA the holder/verifier is interested in (thus arguably violating article 6a.4b mentioned above).\n",
    "\n",
    "A way around some of the privacy concerns is to rely on techniques like those detailed in OCSP Stapling and OCSP Must-Staple. Using those two as an inspiration, the holder could simply perform the revocation check prior to presenting the PID/(Q)EAA to the verifier. While a drastic improvement over regular OCSP, these techniques are only suitable for environments where all actors are honest and non curious, which is not a valid assumption for ecosystems that have a higher proportion of private sector actors but may be valid for an ecosystem with primarily public sector actors.\n",
    "\n",
    "The OCSP is highly mature and has low complexity, which makes it easy to deploy. However, the protocol is designed for X.509 certificates only. Consequently, OCSP does not harmonize well with using other (modern) technologies and data formats, including the ones currently under consideration in the eIDAS Expert Group and EBSI for use in electronic attestations of attributes and Person Identification Data.\n",
    "\n",
    "**Bit vector (BV) based approaches** use bit vectors as a base data structure to perform set membership tests. In essence, instead of keeping a list of unique VC identifiers, a bit vector encodes validity status information as a list containing only [0,1]. Below we cover two commonly used approaches: a Bloom Filter Cascade (BFC) based one, and a Certificate Revocation Vector (CRV) based one.\n",
    "Bloom Filter Cascade\n",
    "\n",
    "A *Bloom Filter Cascade (BFC)* approach uses Bloom filters. A standard Bloom filter is an append only data structure that can be used for set membership tests (recall that all validity status checks are essentially set membership tests). The set membership test, i.e., whether or not an element is in the set, that a Bloom filter performs allows for false positives but not for false negatives. In other words, a query would return either “element is possible in set” or “definitely not in set”. So, if a Bloom filter is used to create a bit vector of still valid VC information, then a query using a particular identifier will return either a “VC is possibly still valid” or a “VC is definitely still valid”.\n",
    "\n",
    "To handle cases where the query returns a “possibly still valid”, one can use multiple Bloom filters. The second Bloom filter would then contain all the revoked identifiers. The second Bloom filter is created using the identifiers that return “possibly still valid” but this time the Bloom filter is used to create a bit vector of the revoked PID/(Q)EAA identifiers. Checking a “possibly still valid” VC against this list returns either a “possibly revoked” or “definitely revoked”. A third Bloom filter can be created for the still uncertain identifiers and so on. Using such a cascade of Bloom filters, it is possible to reduce the false-positive rate.\n",
    "\n",
    "One example implementation is CRLite. It uses a Bloom filter cascade where false positives are stored into another Bloom filter that tests for the opposite value. In other words, the possibly in set values are stored in another Bloom filter where their opposite value (e.g., from a is revoked test to a is not revoked test) is tested. Since Bloom filters do not allow false negatives, such an alternation eventually reaches a Bloom filter with no false-positive entries.\n",
    "\n",
    "There are some efficiency issues with a BFC based approach. The BFC approach optimizes for storage efficiency, but requires more computational resources than a basic CRL. The exact efficiency impact depends on how the bloom filter is designed. Bloom filters can be designed to reduce memory operations at the expense of overall memory requirements, or the opposite (cf. https://hur.st/bloomfilter/). The revocation information also increases over time with cascading, although at a much slower pace than with traditional CRLs.\n",
    "\n",
    "In contrast to a CRL, it is not possible to recover the elements in the set from a BFC. In other words, Bloom filters allow for a particular type of set membership tests, but they do not reveal all elements in the set in the same way a CRL would. The three privacy requirements with relation to BFC:\n",
    "\n",
    "* Separation - The issuer and the validity status provider can be separate entities. The validity status provider has no way to extract knowledge about the identifiers included in each BFC.\n",
    "* Uncorrelatability - There is no information in the BFC that is correlatable. But an entity can, theoretically, reverse engineer the BFC.\n",
    "* Data minimization - It is possible to design a solution where the validity status provider will not learn the identifier of the requested PID/(Q)EAA as long as the parameters of the BFC are known to the requester (who then includes the bit vector of interest in their query).\n",
    "\n",
    "Overall, a BFC based approach offers privacy benefits that may make it suitable for certain contexts where the privacy / deployability / efficiency tradeoffs are worth it.\n",
    "\n",
    "Deployability is adversely affected by increased complexity. The false positive rate approaches 100% (eventually) with every added element in every Bloom filter. It is therefore important to set the parameters of the Bloom filter in a way that matches the expected volume. While not difficult, it is still a relatively complex validity status mechanism when compared to CRL and OCSP. However, the approach has increased support for privacy, which makes it a potential candidate to use with more privacy preserving formats.\n",
    "\n",
    "In contrast to a Bloom filter where the bit vector stores a collection of hash digests, a *Certificate Revocation Vector (CRV)* based approach uses a single bit to represent the revocation status of a VC. For instance, a 1 could present yes and a 0 a no. A validity status service provider maps the VC identifier to an index value and a set membership test is done by checking the index value of the bit vector. One example of the CRV approach is the W3C Revocation List 2020 specification.\n",
    "\n",
    "There exist multiple variations of the CRV approach, each with a slight difference. For instance, some would require including a revocation number as an additional attribute in the VC. Others would not require any specific attribute, but would instead sort the VC set according to some ordering logic. Regardless of approach, all CRVs enable validity status checks the same way. A validity status service provider maintains a database of issuer signed CRVs. To check the revocation status of a VC, the Verifier requests the CRV that contains the VC validity status. \n",
    "\n",
    "Efficiency is in general similar to CRLs, but CRVs can be orders of magnitude smaller than CRLs, which positively impacts efficiency/timeliness.\n",
    "\n",
    "Since the entire CRV is sent, as is the case with CRLs, the CRV approach has similar privacy characteristics to a CRL. The W3C variant of the CRV is essentially a highly efficient generalization of the CRL revocation status mechanism. Similarly, the W3C Status List 2021 can be viewed as a highly efficient list based validity status approach. The three privacy factors in relation to CRV:\n",
    "\n",
    "* Separation - It is possible to separate the issuer and the validity status service provider. The issuer / validity service provider can only learn that the PID/(Q)EAA of interest is in a given set even when colluding. This set can be very large and in some cases include the entire population, at which point colluding actors learn no additional information.\n",
    "* Uncorrelatability - The index value is a correlatable value and colluding actors can use the index value to map out holder usage patterns.\n",
    "* Data minimization - Requesting a CRV can inform the CRV provider what credential set the holder/verifier is interested in. The increased size of CRVs greatly reduces this risk when compared to a CRL. Given their size, it is possible to host a signed CRV on a public Verifiable Data Registry. \n",
    "\n",
    "Deployability is limited. There is a lack of mature standards and to the best of our knowledge, the existing standards do not support legacy PKI infrastructures well. The lack of legacy support comes from the need to include a revocation number in the VC. There exist other ways of ordering the CRV, but these ways will likely always be context specific (e.g., in mDL ordering can be done using expiration dates).\n",
    "\n",
    "The specification is currently a W3C draft community group report and is thus not a mature standard, but the solution components are simple and the approach is already implemented in production by multiple organizations including Microsoft, DigitalBazaar, AFFINIDI, Workday, Ping Identity, and others.\n",
    "\n",
    "Bit vector based approaches can be further privacy enhanced using additional techniques. These techniques increasingly optimize for privacy and the expense of other parameters, often efficiency, efficiency and/or deployability. We refer to these techniques jointly as advanced bit vector based approaches (ABV).\n",
    "\n",
    "One option is to use Secure Multi-Party Computation (SMPC), which would enhance privacy in cases with smaller CRVs and where the ecosystem actors may both be curious and collude. For instance, a SMPC technique may reveal to the validity status service provider only the intersection between two sets, or the cardinality of such an intersection, or nothing at all. Intersection cardinality proofs are useful if we want to provide a validity service in such a way that the validity status service provider cannot learn the requested index, but only the validity status of the requested index. And if it is important that the validity status service provider learns nothing at all, then it is possible to use purpose designed Private Information Retrieval techniques. Within each option, there are multiple techniques and the suitable choice depends on the features we require and the assumptions we have about the participants.\n",
    "\n",
    "Intersection tests can be trivially easy to implement and can have a relatively high efficiency but with certain limitations to privacy. Because there is a wide variety of techniques that can be used for privacy preserving CRV queries, it becomes difficult to assign a single efficiency assessment score for CRVs. In general, increasing privacy comes at the cost of efficiency. \n",
    "Timeliness is interesting. Using advanced bit vector based approaches, it becomes possible to request a revocation status directly from the validity status service provider without revealing the particular index of interest (think of this option as akin to a privacy preserving OCSP). A verifier can thus get timely revocation information without the validity status provider necessarily learning the index value. In the basic approach, where the validity status service provider receives and stores the bit vector as plaintext, the efficiency is very attractive in comparison to other more privacy focused techniques explored herein. Such a basic approach can also be efficiently applied to very large input sets with billions of entries and work well in both centralized, decentralized, and hybrid systems.\n",
    "\n",
    "Privacy is where advanced bit vector approaches can really shine. Even the most basic approach can successfully hide the index value requested. The validity status provider learns nothing more than what the validity status result is (which can be used to identify an individual if that set is small enough). More advanced versions can hide both the index requested and the validity status response from the validity status provider. But these variants incur a massive performance penalty.\n",
    "\n",
    "The three privacy factors in relation to advanced query techniques:\n",
    "\n",
    "* Separation - It is possible to separate the issuer and the validity status service provider. No entity, other than the holder, can learn anything in addition to the results of the validity status check.\n",
    "* Uncorrelatability - An improvement over CRV insofar that the index value is not shared.\n",
    "* Data minimization - Requesting a CRV does not contain any information about what credential set the holder/verifier is interested in beyond what can be deduced from the validity status response. More advanced variants can also hide the validity status response from the validity status provider, who then learns nothing at all. However, this level of privacy introduces other challenges and the options we are aware of all incur significant performance penalties and are complex.\n",
    "\n",
    "There are currently no standards or specifications that we are aware of, but there exist several industry implementations that warrant further investigation in use cases with high privacy requirements. Both Apple and Google are examples of companies that are actively exploring and/or using private set intersection. And Avast is investigating ways to enhance CRVs with Zero Knowledge Proofs (a special case of secure two-party computation). The area is also a very active research topic and there exist several suitable candidates for further evaluation.\n",
    "\n",
    "**Accumulators** can be used to create revocation status solutions with a very strong emphasis on privacy over other parameters. An accumulator is a single data element that is created using other data elements and where the accumulator does not reveal details about the included elements. An illustrative example is the multiplication of two prime factors into a composite number. The resulting composite number is a single data element that is created using the two prime factor elements. \n",
    "\n",
    "Another example is the above described basic Bloom filter, which is in fact a symmetric (does not use asymmetric cryptography) and static (does not support removal of elements) accumulator. Accumulators that allow for data updates (i.e., both insertion and deletion of elements) are referred to as dynamic accumulators. Accumulators can further be divided into those that allow for only set membership proofs, only set non-membership proofs, or those that allow for both. Finally, there are types of accumulators that are constructed using a trusted entity and there are those that are constructed without having to rely on a trusted entity. There is no known construction that is efficient, does not rely on a trusted entity, and that has high privacy properties. The choice of accumulator is, like most other things, a selection of parameters to optimize for.\n",
    "\n",
    "Regardless of the specific accumulator type, in a revocation status context, the data elements added to the accumulator can be commitments to PID/(Q)EAA identifiers. As such, accumulators can be used to perform membership tests. For instance, it is possible to construct an accumulator from all still valid PID/(Q)EAAs using their respective identifiers, and if the holder can prove that a certain identifier is part of the accumulator, then the associated PID/(Q)EAA is not revoked.\n",
    "Efficiency/Timeliness and accumulators\n",
    "There are many ways to construct accumulators. One interesting property of accumulators is that their size can remain constant independent of the number of elements that are added to them (not a unique property to accumulators). The  exact storage requirements depend on the type of accumulator used, but in general, cryptographic accumulators are quite space-efficient and enable constant-time set membership tests. \n",
    "\n",
    "While the set membership test can be rather efficient, the computation of the actual accumulator value is generally computationally costly. The computational resource requirements depend on the type of accumulator used, but these resource requirements can be quite extensive and prohibit large scale deployment. For instance, asymmetric RSA accumulators require generation of (often large) Sophie Germain primes, mapping of said primes to PID/(Q)EAAs, and updating an accumulator with all the PID values. Primality tests are time consuming. Similarly, in accumulators where the order of the group is unknown the issuer cannot efficiently compute the inverses (required for something known as the witness). And if we want Zero Knowledge Proof (ZKP) properties, additional requirements apply and the approach becomes marginally more complex.\n",
    "\n",
    "Timeliness is interesting because the accumulator value can be published without any privacy concerns. As such, it is possible for a holder to generate a validity status proof when needed. However, updating the accumulator value can be costly, especially for accumulators containing many values, which means that an issuer may be limited to updating the accumulator on a daily basis. And updates can require (depending on the accumulator) the distribution of a delta that a holder can use for their validity status proof generation. This delta can also be published. Publishing the accumulator value and the delta values is preferable in cases where network limitations prevent efficient communication between all relevant parties.\n",
    "\n",
    "Accumulators can have very strong privacy properties. If a single random value is accumulated, then the accumulator cannot leak any information about the accumulated set of PID/(Q)EAA commitments or the accumulator witness. Consequently, it is possible to publish both the accumulator value, and any potential deltas, with no privacy implications.\n",
    "\n",
    "The three privacy factors in relation to accumulators in general (variations may have different properties):\n",
    "\n",
    "* Separation - It is possible to separate the issuer and the validity status service provider. In fact, the revocation status object can be made public. This is an interesting property since this also means that revocation object updates do not leak information about either additions or removals. Separation is so strong here that the validity status provider does not learn anything about any element in the revocation object, and all updates are privacy preserving too.\n",
    "* Uncorrelatability - The set membership proof, or non membership proof, the holder performs reveals no correlatable information. Such a proof can be done in interactions that are non ZKP or ZKP based.\n",
    "* Data minimization - Since the revocation object can be stored publicly, there is no information that is revealed during access, and the holder can generate a revocation status proof without notifying the validity status service provider.\n",
    "\n",
    "Privacy capabilities are, however, conditioned on some deployment considerations as described next.\n",
    "\n",
    "The above privacy properties sound enticing, but given the efficiency constraints of accumulators, practical implementations may impact privacy. For instance, performance considerations may force an issuer to limit the size of an individual accumulator object to between 1 000 to 10 000 elements. And the verifier will always know which accumulator object the holder used for the non revocation proof, which then becomes a correlatable factor and effectively provides as much privacy as the size of the accumulator. It remains to be seen if the efficiency issues can be overcome so that communicating the accumulator used only incurs a limited loss of privacy.\n",
    "\n",
    "A well known implementation that relies on dynamic accumulators and distributed ledgers is the revocation method defined in Hyperledger Indy and used in AnonCreds (hereafter referred to as Indy AnonCreds). This revocation method allows a holder to generate a validity proof using a Zero Knowledge Proof of accumulator inclusion.\n",
    "\n",
    "Accumulators remain an active area of development and there are many different implementations with different properties and optimizations. Accumulators have been widely adopted in the cryptocurrency space both for space efficiency reasons but also for their privacy properties. For instance, accumulators are actively used to prove that a transaction is part of a set of transactions that have been committed to the blockchain.\n",
    "\n",
    "One potential challenge with most accumulator based revocation status checks is that they are quite novel, and often complex, constructions that are conceptually quite different from most of the other approaches listed herein. Contrast this with a CRV based approach, that is both simple to understand and conceptually similar to existing approaches like CRLs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdf618b-fc0e-418b-a764-39a05a808232",
   "metadata": {
    "tags": []
   },
   "source": [
    "## EBSI architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0de5f1-d99d-41be-b8c9-b327d8ae1026",
   "metadata": {},
   "source": [
    "Below is a high level depiction of the BESI architecture. All the information below is from the [EBSI Documentation area](https://ec.europa.eu/digital-building-blocks/wikis/display/EBSIDOC/Architecture).\n",
    "\n",
    "<img src =\"https://ec.europa.eu/digital-building-blocks/wikis/download/attachments/555222764/ebsiarchi8_ebsi-doc.png?version=6&modificationDate=1657793391187&api=v2\" alt=\"High level view of the EBSI architecture\" width =\"800\">\n",
    "\n",
    "Each layer is described next.\n",
    "\n",
    "### The infrastructure layer\n",
    "\n",
    "The infrastructure layer contains all the elements needed to setup the required EBSI infrastructure. This includes network, compute and deployment capabilities. The infrastructure layer makes deploying and running an EBSI node rather straight forward. Assuming the [minimum technical requirements](https://ec.europa.eu/digital-building-blocks/wikis/display/EBSIDOC/Minimum+Technical+Requirements+for+EBSI+V2.0+for+an+EBSI+Node) are met, an EBSI node operator can use the supplied host images to launch their node. The entire process is automated and there are additional services that help with configuration and testing (more information is provided at the dedicated [infrastructure layer space](https://ec.europa.eu/digital-building-blocks/wikis/display/EBSIDOC/Infrastructure+Layer) on the EBSI documentation)\n",
    "\n",
    "Once the EBSI node is up and running, it is possible to log in using a terminal. `docker ps` lists the running docker containers for each higher layer service. Adding additional capabilities to EBSI is technically rather easy. For instance, when support for the Interplanetary File System (IPFS) was added to the Swedish dev node, it was done using a docker container.  \n",
    "\n",
    "### The chain and storage layer\n",
    "\n",
    "The chain and storage layer includes the DLT protocols supported by EBSI and adds additional off chain storage solution support. The off chain storage support was added because DLT is not fit for storing large amounts of data or for storing data that falls under GDPR. The off chain storage capabilities of EBSI currently support:\n",
    "\n",
    "1. flat file types of storage\n",
    "2. relational data bases\n",
    "3. key/value stores\n",
    "4. big data stores\n",
    "\n",
    "As aforementioned, the Swedish dev node supports distributed file systems using IPFS in addition to the existing [distributed storage solution on EBSI](https://ec.europa.eu/digital-building-blocks/wikis/display/EBSIDOC/Distributed+Storage) that uses Cassandra DB.\n",
    "\n",
    "Note that EBSI is not one DLT network, but aims to support multiple DLT networks as required by the market and the member states. The Swedish dev node is currently experimenting with adding support for Indy based VC networks.\n",
    "\n",
    "In addition to off chain storage, EBSI also supports DLT storage using Smart Contracts for Besu (or, equivalently, chain code for Fabric but this text uses smart contract to refer to both). Codified logic that is essential for higher level services is stored in smart contracts. The following smart contracts are defined for EBSI v2.0:\n",
    "\n",
    "1. DID registry\n",
    "2. TimeStamp\n",
    "3. Trusted Apps registry\n",
    "4. Trusted Issuers registry\n",
    "5. Trusted Ledgers and smart contracts registry\n",
    "6. Trusted policies registry\n",
    "7. Trusted schemas registry\n",
    "\n",
    "Each service has an API and the list of all APIs is available on the [API test pages](https://api.test.intebsi.xyz/docs/apis) together with source code. However, these resources sometimes return a 404, are behind a login, require a token even for testing, or just do not load (e.g., at the time of this writing, https://api.ebsi.xyz/docs/ did not load). Consequently, it is often very difficult to use EBSI for proof of concepts and early demonstrators. Relatedly, what is possible to access (e.g., the [schema page for a DID Document](https://api.preprod.ebsi.eu/docs/apis/did-registry/latest#/schemas/DIDDocument)) is rather underwhelming as the example provided is simply: `{\"@context\": \"http://example.com\"}`.\n",
    "\n",
    "The **DID registry** smart contract is a core EBSI service for storing DIDs and the associated DID Documents on EBSI. The DID registry also enables the following interactions CRUD operations of DID and DID Documents (delete is not supported as DID controllers are revoked and not deleted). The [EBSI Documents page for DID registry](https://ec.europa.eu/digital-building-blocks/wikis/display/EBSIDOC/DID+Registry+Smart+Contract) is a great source for additional information and is especially relevant for developers seeking to interact with EBSI. Note that the page includes an incorrect flows with creating and anchoring a DID on EBSI. This flow is currently not correct as it suggests that natural persons should register their DID and DID Documents publicly, which is absolutely not the case. There are many different DID strategies and hundreds of DID methods (the W3C keeps a [list](https://w3c.github.io/did-spec-registries/#did-methods)), and EBSI is DID format and strategy agnostic. All EBSI registered DIDs are in the form `did:ebsi:<uri>`.\n",
    "\n",
    "The **TimeStamp** smart contract is a core service that enables the timestamping of file hashes and file metadata hashes.(https://api.test.intebsi.xyz/docs/apis/timestamp/latest#/).\n",
    "\n",
    "The **Trusted Apps registry** smart contract acts a generic trust anchor for all core service APIs and for external trusted applications. The service provides access management for applications on EBSI.\n",
    "\n",
    "The **Trusted Issuers registry** smart contract is a generic trust anchor for TAI accredited trusted issuers. The registry lists each trusted issuer and the objects each specific issuer can issue. Using the public DID of an issuer, a holder can verify that the issuer is on the trusted issuers registry and thus able to issue EBSI VC.\n",
    "\n",
    "The **Ledgers and smart contracts registry** contains information about ledgers on EBSI, the **Trusted Policy registry** contains information about accessibility rules, and the **Trusted Schemas registry** contains information about how to validate the data formats in the UCAD exchanges.\n",
    "\n",
    "### The core services layer\n",
    "\n",
    "The core services layer includes all the services that the higher level use cases can access. Use cases do not access lower level services directly, instead they do so indirectly using the core services layer. In this capacity, the core services layer represents a collection of interfaces exposed to the outside world. The following core services exist:\n",
    "\n",
    "1. Identity\n",
    "2. API Security Management\n",
    "3. Integration Tools\n",
    "4. Trusted Registries API\n",
    "5. Integration API\n",
    "\n",
    "Out of the above, the **identity core service** is the most relevant for the purposes of this text. It is the identity core service that exposes the required access to interact with EBSI VC and EBSI verifiable presentations. All use case applications using UCAD require identity. Some require the service provider to identify itself, others the service to identify itself, others still the holder. The identity core service supports a variety of identity solutions and is highly dependent on evolving work in eIDAS and the GDPR. There is also support for DID Auth and concepts like ID Hub. Finally, the EBSI supports also use cases where the identification and identity management is performed at the application level. The identity core service exposes the following APIs:\n",
    "\n",
    "* Verifiable Presentation API and Library\n",
    "* Proxy Data Hub API\n",
    "* DID Authentication API\n",
    "* Verifiable Credentials API and Library\n",
    "* DID Registry API (explained above)\n",
    "\n",
    "The Verifiable Presentation API and Library enables the creation of W3C based verifiable presentations for signing and the verification of W3C verifiable presentations. In EBSI v 2.0, the service is made available via a library. Presently, the library only supports JSON W3C VC (for details see this [comparison on W3C VC formats](https://www.w3.org/TR/vc-imp-guide/#benefits-of-jwts)). In EBSI, the support is currently limited to secp256k1 signatures or eIDAS QTSPs generating eIDAS seals that the holder includes as a JWS. This means that a lot of privacy features are not possible to test today on EBSI. The flow is shown below.\n",
    "\n",
    "<img src=\"https://ec.europa.eu/digital-building-blocks/wikis/download/attachments/555222779/IssueVP.png?version=1&modificationDate=1657281319277&api=v2\" alt=\"Flow of verifiable presentation issuance\" width=\"500\">\n",
    "\n",
    "The Proxy Data Hub API is a service that provides the capability of managing secure storage for a VC holder. The service aims to let the user select the storage repository, but in EBSI v2.0 only Cassandra DB is supported. A lot of features are still in the planning stage and are not yet mature or ready for testing.\n",
    "\n",
    "The DID Authentication API is a service for challenge response authentication using DIDs in a RESTful way. The DID Auth is an extension of the OAauth2 and OIDC protocols with support for DIDs. In EBSI, DID Auth is implemented across two different libraries. The first is `ebsi-oauth2-auth`, which is focused on access management for components and users. The second is `ebsi-siop-auth` and is focused on natural and legal person authentication with OIDC with challenge response authentication using DIDs. Again, the only keys supported are hex formatted `secp256k1`. This is a limitation for many use cases that require privacy.\n",
    "\n",
    "The Verifiable Credentials API and Library enables the creation of W3C VC. As mentioned above, only JSON W3C is supported presently. This means that there is no support for many desired privacy and user control features in EBSI at this moment that are crucial for UCAD. There is ongoing work in IETF to standardize JSON Web Token documents that support privacy features like selective disclosure, but this work is still in draft stages. Also, all the associated code is behind [a login](https://ec.europa.eu/digital-building-blocks/code/login?next=/projects/EBSI/repos/verifiable-credential-api/browse) so it is not possible to use it in a local environment.\n",
    "\n",
    "<img src=\"https://ec.europa.eu/digital-building-blocks/wikis/download/attachments/555222800/issueVC.png?version=1&modificationDate=1657281319983&api=v2\" alt =\"Flow of verifiable credential issuance\" width=\"500\">\n",
    "\n",
    "To conclude, while EBSI has a lot of potential, this potential is largely unrealized today and remains largely unaccessible for outside developers and actors trying to develop proof of concepts and early demonstrators. Experiences from actors who have successfully completed the EBSI wallet conformance tests are that it is often difficult to get access to resources, that the code base is not open, that there is a lack of community support, and that several key features are still under development. While the testing process itself is smooth, the access may be challenging and thus prohibit ease of experimentation. For instance, EBSI does not support community defined credential definitions and schemas. And a lot of the validation processes for EBSI registry inclusion is manual and highly time consuming. Also, since a lot of the resources and material are black boxed, it is not suitable for learning purposes. Consequently, the labs and the tests that will be presented next are done using a more developer and test friendly environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f0e50b-c329-4efa-aabd-74fa39ce23f6",
   "metadata": {},
   "source": [
    "# Labs and demos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eed3251-5703-4fcc-b1a3-31a53d2547ce",
   "metadata": {},
   "source": [
    "This section presents ongoing work with several key topics that are important for developers and those aiming to implement EBSI VC. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7daed1f1-ecea-4c5a-8cf6-8b301a241e07",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Selective disclosure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889ee93a-1f63-4158-917e-26636b3fe453",
   "metadata": {},
   "source": [
    "Selective disclosure is the ability for a holder to choose what and how much data from a VC they share on a case-by-case basis. Selective disclosure can be achieved in multiple different ways, each way has different properties:\n",
    "\n",
    "1. Just in time issuance - contact the issuer at request time. This approach is also known as selective release.\n",
    "2. Trusted witness - a witness mediates the information disclosure. \n",
    "3. Cryptographic solutions - use a cryptographic technique to disclose a subset of information from a larger assertion set (possibly also claims from multiple separately issued VC).\n",
    "\n",
    "Option 1 and 2 without 3 is not UCAD and will be ignored here. Option 3 in turn can be broken down into multiple possible ways. The [W3C VC implementation guidelines](https://www.w3.org/TR/vc-imp-guide/#selective-disclosure) provides some insights into these ways.\n",
    "\n",
    "1. Atomic credentials are single claim VC. These have tons of problems so they will not be discussed here.\n",
    "2. Signatures over a logical grouping of a hash digest set. This approach relies on well established cryptographic primitives to create a signature over a logical ordering of digests. The holder provides the signature and a knowledge proof (note not ZKP) and can select what claims to reveal. The method has several benefits related to simplicity, but has some privacy drawbacks and lacks certain more novel features.\n",
    "3. Multi message signatures that allow a holder to disclose only those claims which need to be revealed to a verifier, rather than requiring all of the credential's claims to be revealed. These are interesting because they often enable the holder to disclose also predicate proofs. For instance, given a claim in a VC of birth date, the holder can generate a predicate `AgeOverX` proof. The downside is that this approach is far more complex than the second one and that it is not yet widely supported in standards and specifications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a63c62-a3b8-4da9-b701-d3cee513b4db",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Example with logical grouping of salted hash digests for SD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a69f63-bff0-48cd-b969-e6050b7ded3a",
   "metadata": {},
   "source": [
    "We rely on ISO/IEC 18013-5 for our example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93824fb-2737-453f-9fd5-8ff34f64f669",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Crypto.Util import number\n",
    "from Crypto.Hash import SHA256\n",
    "from ecdsa import SigningKey, NIST256p\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e0a5d4-7984-4f1d-b08c-dd3b9dd8dd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The ISIs, I will convert it to json and python by removing h' and instead adding 0x.\n",
    "# Note that the example below generates digests that differ from the Annex D example.\n",
    "# Note also that I do not convert to CBOR because it is not required to understand the principle.\n",
    "# See the bullet points under the \"Data structure examples from Annex D\" for change details\n",
    "# See the ISO/IEC 18013-5 for details on the keys\n",
    "\n",
    "isi_0 = '''{\n",
    "\"digestID\": 0,\n",
    "\"random\": \"0x8798645B20EA200E19FFABAC92624BEE6AEC63ACEEDECFB1B80077D22BFC20E9\",\n",
    "\"elementIdentifier\": \"family_name\",\n",
    "\"elementValue\": \"Doe\"\n",
    "}'''\n",
    "\n",
    "isi_3 = '''{\n",
    "\"digestID\": 3,\n",
    "\"random\": \"0xB23F627E8999C706DF0C0A4ED98AD74AF988AF619B4BB078B89058553F44615D\",\n",
    "\"elementIdentifier\": \"issue_date\",\n",
    "\"elementValue\": \"2019-10-20\"\n",
    "}'''\n",
    "\n",
    "isi_4 = '''{\n",
    "\"digestID\": 4,\n",
    "\"random\": \"0xC7FFA307E5DE921E67BA5878094787E8807AC8E7B5B3932D2CE80F00F3E9ABAF\",\n",
    "\"elementIdentifier\": \"expiry_date\",\n",
    "\"elementValue\": \"2024-10-20\"\n",
    "}'''\n",
    "\n",
    "isi_7 = '''{\n",
    "\"digestID\": 7,\n",
    "\"random\": \"0x26052A42E5880557A806C1459AF3FB7EB505D3781566329D0B604B845B5F9E68\",\n",
    "\"elementIdentifier\": \"document_number\",\n",
    "\"elementValue\": \"123456789\"\n",
    "}'''\n",
    "\n",
    "# Note that ISI 8 is truncated\n",
    "isi_8 = '''{\n",
    "\"digestID\": 8,\n",
    "\"random\": \"0xD094DAD764A2EB9DEB5210E9D899643EFBD1D069CC311D3295516CA0B0244\",\n",
    "\"elementIdentifier\": \"portrait\",\n",
    "\"elementValue\": \"0xFFD8FFE...FFD9\"\n",
    "}'''\n",
    "\n",
    "isi_9 = '''{\n",
    "\"digestID\": 9,\n",
    "\"random\": \"0x4599F81BEAA2B20BD0FFCC9AA03A6F985BEFAB3F6BEAFFA41E6354CDB2AB2CE4\",\n",
    "\"elementIdentifier\": \"driving_privileges\",\n",
    "\"elementValue\":\n",
    "[\n",
    "{\n",
    "\"vehicle_category_code\": \"A\",\n",
    "\"issue_date\": \"2018-08-09\",\n",
    "\"expiry_date\": \"2024-10-20\"\n",
    "},\n",
    "{\n",
    "\"vehicle_category_code\": \"B\",\n",
    "\"issue_date\": \"2017-02-23\",\n",
    "\"expiry_date\": \"2024-10-20\"\n",
    "}\n",
    "]\n",
    "}'''\n",
    "\n",
    "isi_0 = json.loads(isi_0)\n",
    "isi_3 = json.loads(isi_3)\n",
    "isi_4 = json.loads(isi_4)\n",
    "isi_7 = json.loads(isi_7)\n",
    "isi_8 = json.loads(isi_8)\n",
    "isi_9 = json.loads(isi_9)\n",
    "\n",
    "# Now we generate the valueDigests\n",
    "valueDigest_0 = SHA256.new()\n",
    "valueDigest_0.update(bytes(str(isi_0), 'utf-8'))\n",
    "valueDigest_3 = SHA256.new()\n",
    "valueDigest_3.update(bytes(str(isi_3), 'utf-8'))\n",
    "valueDigest_4 = SHA256.new()\n",
    "valueDigest_4.update(bytes(str(isi_4), 'utf-8'))\n",
    "valueDigest_7 = SHA256.new()\n",
    "valueDigest_7.update(bytes(str(isi_7), 'utf-8'))\n",
    "valueDigest_8 = SHA256.new()\n",
    "valueDigest_8.update(bytes(str(isi_8), 'utf-8'))\n",
    "valueDigest_9 = SHA256.new()\n",
    "valueDigest_9.update(bytes(str(isi_9), 'utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3610a26e-18f4-4c3e-a459-6aa9bcb8a01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the disclosed ISI values above, we include the SHA256 digest. \n",
    "# For the values not disclosed in an ISI above, the digests come from Annex D.\n",
    "\n",
    "# Note that the digests for {1,2,5,6,10,11,12} is salted in each `MobileSecurityObject` \n",
    "# and the ones below are specific for the example in Annex D\n",
    "\n",
    "valueDigests = {\n",
    "    \"0\": valueDigest_0.hexdigest(),\n",
    "    \"1\": hex(0x67E539D6139EBD131AEF441B445645DD831B2B375B390CA5EF6279B205ED4571)[2:],\n",
    "    \"2\": hex(0x3394372DDB78053F36D5D869780E61EDA313D44A392092AD8E0527A2FBFE55AE)[2:],\n",
    "    \"3\": valueDigest_3.hexdigest(),\n",
    "    \"4\": valueDigest_4.hexdigest(),\n",
    "    \"5\": hex(0xFAE487F68B7A0E87A749774E56E9E1DC3A8EC7B77E490D21F0E1D3475661AA1D)[2:],\n",
    "    \"6\": hex(0x7D83E507AE77DB815DE4D803B88555D0511D894C897439F5774056416A1C7533)[2:],\n",
    "    \"7\": valueDigest_7.hexdigest(),\n",
    "    \"8\": valueDigest_8.hexdigest(),\n",
    "    \"9\": valueDigest_9.hexdigest(),\n",
    "    \"10\": hex(0xC98A170CF36E11ABB724E98A75A5343DFA2B6ED3DF2ECFBB8EF2EE55DD41C881)[2:],\n",
    "    \"11\": hex(0xB57DD036782F7B14C6A30FAAAAE6CCD5054CE88BDFA51A016BA75EDA1EDEA948)[2:],\n",
    "    \"12\": hex(0x651F8736B18480FE252A03224EA087B5D10CA5485146C67C74AC4EC3112D4C3A)[2:]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0a4a25-f9de-4564-b696-c70f68179986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The SHA256 digest of the valueDigest dict we generated in the cell above is computed\n",
    "device_signature = SHA256.new()\n",
    "device_signature.update(bytes(str(valueDigests), 'utf-8')) # This illustration SHA256(valueDigests)\n",
    "msg = device_signature.hexdigest().encode('utf-8')\n",
    "\n",
    "# Generate the device signing and verification keys\n",
    "device_sign_key = SigningKey.generate(curve=NIST256p) # The possible cipher suites are defined in clause 9.1.5.2\n",
    "device_verify_key = device_sign_key.verifying_key\n",
    "signature = device_sign_key.sign(msg)\n",
    "\n",
    "assert device_verify_key.verify(signature, msg) == True # Makes sure the signature can be verified"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877039b7-5ab5-4cea-8353-80ebcdb1b05c",
   "metadata": {},
   "source": [
    "We assume the verification key is shared somehow. We assume also that the issuer authentication is done. We care here only about showing how selective disclosure is done using the following example flow:\n",
    "\n",
    "1. The verifier asks the mdoc holder for `driving_privileges` found in ISI with `digestID` 9\n",
    "2. The holder sends over \n",
    "    1. the `valueDigests` \n",
    "    2. the `isi_9` in plaintext\n",
    "    3. the signed msg (which is a signature over a logical grouping of ISI digests)\n",
    "3. The verifier checks that the disclosed ISI (plaintext) is part of the signed msg\n",
    "    \n",
    "    \n",
    "**Steps 1 and 2.** The verifier asks for `driving_privileges`\n",
    "\n",
    "The holder sends over the below document (note that the random value would be different in each ISI)\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"digestID\": 9,\n",
    "  \"elementIdentifier\": \"driving_privileges\",\n",
    "  \"elementValue\": [\n",
    "    {\n",
    "      \"expiry_date\": \"2024-10-20\",\n",
    "      \"issue_date\": \"2018-08-09\",\n",
    "      \"vehicle_category_code\": \"A\"\n",
    "    },\n",
    "    {\n",
    "      \"expiry_date\": \"2024-10-20\",\n",
    "      \"issue_date\": \"2017-02-23\",\n",
    "      \"vehicle_category_code\": \"B\"\n",
    "    }\n",
    "  ],\n",
    "  \"random\": \"0x4599F81BEAA2B20BD0FFCC9AA03A6F985BEFAB3F6BEAFFA41E6354CDB2AB2CE4\"\n",
    "}\n",
    "```\n",
    "\n",
    "The holder also sends the signature over the `valueDigests` object:\n",
    "\n",
    "`0x7259c6eac8135df74afc427a6f78891c088db02ca60fd7808044545f2917ec0684731a2d2cdc81d1ccacce23a079e1d2`\n",
    "\n",
    "The holder finally sends the valueDigests. Note that ISI digests for {0,3,4,7,8,9} are different from Annex D due to the changes made for easier illustration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a10edb-fba1-47b1-b869-e751e4130ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "valueDigests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb2f1cc-1051-4049-9c9f-ecbac3b08777",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Example with multimessage signature based approaches for SD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b8e53f-7a43-42c5-bdee-eea2becfb77e",
   "metadata": {
    "tags": []
   },
   "source": [
    "In contrast to the logical ordering of hash digests, the multimessage approach is a lot more complex. One approach that does not require understanding cryptographic pairings is ZKP-CL. This text is aimed at those who seek to understand how the ZKP-CL attestation format (Anoncreds) enables a holder to select which attributes to reveal to a verifier. \n",
    "\n",
    "The Camenisch-Lysyanskaya (CL) signature scheme is a multi message capable signature scheme that was developed in a series of papers ([CL01](https://eprint.iacr.org/2001/019.pdf), [CL02](https://cs.brown.edu/people/alysyans/papers/camlys02.pdf), [CL03](http://cs.brown.edu/people/alysyans/papers/camlys02b.pdf), [CL04](https://www.iacr.org/archive/crypto2004/31520055/cl04.pdf)). To understand CL signatures, it is important to understand both the [Discrete Log Problem](https://www.doc.ic.ac.uk/~mrh/330tutor/ch06s02.html#:~:text=The%20discrete%20logarithm%20problem%20is,logarithms%20depends%20on%20the%20groups.) and how [commitment schemes](https://en.wikipedia.org/wiki/Commitment_scheme) work.\n",
    "\n",
    "The example herein is developed using mainly [CL01](https://eprint.iacr.org/2001/019.pdf). As such, the example differs from the way Anoncreds v 0.7 handles selective disclosure (cf. section 4.7.4 in Lodder, Zundel, and Khovratovich, 2019). To simplify the illustration of the selective disclosure mechanism, several steps outlined in 4.7.4 are missing. Specifically, the example below:\n",
    "\n",
    "* does not use a nonce\n",
    "* assumes that all attributes exist in a single attestation\n",
    "* ignores the setup of the non interactive parts of the proof\n",
    "* only considers the case where the attribute is fully disclosed (as opposed to disclosing statements about the attribute value, which Anoncreds is capable of)\n",
    "* uses a simpler proof verification as a consequence of the points above\n",
    "\n",
    "The CL signatures used in the early Anoncred format were based on the strong RSA assumption (cf. [Wiki on SRSA](https://en.wikipedia.org/wiki/Strong_RSA_assumption)). The actors and their interactions are as follows ([source](https://www.csc.kth.se/~buc/PPC/Slides/jan.pdf)):\n",
    "\n",
    "* An attestation contains $L$ attributes represented as $m_0,\\ldots,m_{L-1}$\n",
    "* An issuer signs a block of messages\n",
    "* The holder presents the messages, or a subset thereof, to a verfier together with the signature\n",
    "* The verifier checks the messages and the signature\n",
    "\n",
    "Steps:\n",
    "\n",
    "* Generate $n=pq$\n",
    "* $R_0, \\ldots, R_{L-1}, S, Z \\in \\mathbf{QR}_n$ (ie., generates $L+2$ random numbers from a [quadratic residue](https://en.wikipedia.org/wiki/Quadratic_residue) modulo $n$)\n",
    "* Public key will be $(n,R_0, \\ldots, R_{L-1}, S, Z)$ \n",
    "* Secret key is $p$\n",
    "* Message space is $\\{(m_0, \\ldots, m_{L-1}): m_i \\in \\pm \\{0,1\\}^{l_m}\\}$\n",
    "* Signing algorithm: on input $(m_0, \\ldots, m_{L-1})$ chose a random prime $e>l_m + 2$ and a random number $v$ of length $l_v = l_n + l_m + l_r$ where $l_r$ is a security parameter\n",
    "* Compute the value $A$ s.t. \n",
    "\n",
    "\\begin{align}\n",
    "  A = \\Bigg(\\frac{Z}{R_0^{m_0} \\cdot \\ldots \\cdot R_{L-1}^{m_{L-1}} \\cdot S^v}\\Bigg)^{\\frac{1}{e}} \\pmod n\n",
    "\\end{align}\n",
    "\n",
    "* The signature on the message $(m_0, \\ldots, m_{L-1})$ consists of $(e,A,v)$\n",
    "\n",
    "Verification of the signature on the message is done through:\n",
    "\n",
    "* $Z \\equiv A^e \\cdot R_0^{m_0} \\cdot \\ldots \\cdot R_{L-1}^{m_{L-1}} \\cdot S^v \\pmod n$\n",
    "\n",
    "The holder can selectively disclose a message by:\n",
    "\n",
    "1. sending $m_i$ to the verifier, who computes $(R_i^{m_i}) \\pmod n$\n",
    "2. compute $(R_i^{m_i}) \\pmod n$, which is the commitment of $m_i$ and sent the commitment to he verifier\n",
    "\n",
    "The holder can send over the messages they wish to fully disclose, and the commitment for the messages they wish to keep secret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d6e053-2d01-46a8-878e-fd48ff2828f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Crypto.Util import number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e18b1c-6208-4ce4-ae26-3ad4a00911e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this example we use two messages\n",
    "\n",
    "# For demo purposes to make print more readable\n",
    "p = number.getPrime(32)\n",
    "q = number.getPrime(32)\n",
    "\n",
    "# p = number.getStrongPrime(512)\n",
    "# q = number.getStrongPrime(512)\n",
    "\n",
    "# The public parts\n",
    "n = p*q\n",
    "R_0 = pow(number.getRandomRange(2, n), 2, n)\n",
    "R_1 = pow(number.getRandomRange(2, n), 2, n)\n",
    "S = pow(number.getRandomRange(2, n), 2, n)\n",
    "Z = pow(number.getRandomRange(2, n), 2, n)\n",
    "\n",
    "# The two messages\n",
    "m_0 = number.getRandomRange(2, n)\n",
    "m_1 = number.getRandomRange(2, n)\n",
    "\n",
    "# The signature related parts\n",
    "e = number.getPrime(m_0.bit_length() + 1) # Part of signature\n",
    "e_inv = pow(e, -1, (p-1)*(q-1))\n",
    "v = number.getRandomNBitInteger(m_0.bit_length() + n.bit_length() + 1) # Part of signature\n",
    "\n",
    "commitment_vector = pow(R_0, m_0, n) * pow(R_1, m_1, n) * pow(S, v, n)\n",
    "commitment_vector_inv = pow(commitment_vector, -1, n)\n",
    "\n",
    "A = pow((Z * commitment_vector_inv) % n, e_inv, n) # Part of signature\n",
    "\n",
    "print(f'Public key is:\\nn = {n}\\n(R_0, R_1) = {(R_0, R_1)}\\nS = {S}\\nZ = {Z}')\n",
    "print(f'\\nPrivate key is: {(p,q)}')\n",
    "print(f'\\nMessage (m_0,m_1) is ({m_0}, {m_1}) \\nSignature on (m_0,m_1) is: e = {e}, s = {A}, v = {v}')\n",
    "\n",
    "print('\\nRHS is the same as LHS:', (pow(A, e, n) * commitment_vector) % n == Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cba09e-3ab2-490d-9fe0-f070ced73039",
   "metadata": {},
   "source": [
    "As aforementioned, the example above illustrates selective disclosure using only fully disclosed attributes. Anoncred is capable of more advanced disclosure types, but these are more complex and not strictly necessary to show in order to provide a basic understanding of how Anoncred achieves selective disclosure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b78b001-1c36-4451-9674-5fa2ea6ab79d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Working with Aries, Ursa, and Indy\n",
    "\n",
    "Also, the default settings for the governance stacks are often used since the focus is on the technology stack. More specifically:\n",
    "\n",
    "* Layer 1: establishing cryptographic roots of trust labs:\n",
    "  1. How to establish a secure and privacy connection between two actors.\n",
    "  2. How to verify the identity of the party you are connecting to.\n",
    "  3. Explain the governance choices necessary to enable technical trust on Layer 1.\n",
    "* Layer 2: the agent labs:\n",
    "  1. How to implement digital wallets and agents\n",
    "* Layer 3: data exchange labs\n",
    "  1. Offering, requesting, and creating verifiable credentials\n",
    "  2. Verifying verifiable credentials\n",
    "  3. Enabling advanced features like selective disclosure and predicate proofs\n",
    "\n",
    "Note that the lab numbering will not correspond to the layer numbering. \n",
    "\n",
    "There are many protocols, technologies, implementations etc., mentioned in the text below. To facilitate reading, please se the following terminology/concepts/terms map in [this link](https://user-images.githubusercontent.com/30799110/150362394-5d0319ae-7bad-4674-863c-d6dd35346ea9.png).\n",
    "\n",
    "### General setup guide for the labs\n",
    "\n",
    "The prerequisites for the labs are a computer (with access to Ubuntu 18.04) and a smart phone. All the labs can be run locally on your machine, or using the browser using a service called \"Play with Docker\", which allows you to access a terminal command line without having to install anything locally. If you want to run the labs locally, you will need a terminal CLI running bash shell, [docker](https://docs.docker.com/get-docker/) and [docker-compose](https://docs.docker.com/compose/install/), and [git](https://www.linode.com/docs/guides/how-to-install-git-on-linux-mac-and-windows/). To run the labs in your browser, go to the docker playground http://play-with-von.vonx.io/ (already has all the prerequisites installed). Optionally, if you are not comfortable with CLI, there is this guide that is focused on [openAPI](https://medium.com/@khalifa.toumi/how-to-use-hyperledger-aries-cloud-agent-for-a-classical-workflow-issuer-holder-verifier-9dd595f2f847).\n",
    "\n",
    "#### Lab 1 \n",
    "\n",
    "In Lab 1., we use the demos provided to get a basic feel for how agents work and interact. Follow [this link](https://github.com/PeterAltmann/SSIdemo/blob/main/LAB1.md) for the lab.\n",
    "\n",
    "#### Lab 2\n",
    "\n",
    "In Lab 2. we move beyond the demos and take a closer look at how we can use ACA-Py to provision agents and do basic interactions. Follow [this link](https://github.com/PeterAltmann/SSIdemo/blob/main/LAB2.md) to get to the lab. \n",
    "\n",
    "#### Lab 3\n",
    "\n",
    "In Lab 3. we continue taking a closer look at ACA-Py and see how we can use it to start our own agents and issue a VC within the context of Authentic Company Data. See this [link](https://github.com/PeterAltmann/SSIdemo/blob/main/LAB3.md). \n",
    "\n",
    "#### Lab 4\n",
    "\n",
    "In [Lab 4](https://github.com/PeterAltmann/SSIdemo/blob/main/LAB4.md), we take a closer look at DIDComm and the ways agents can connect.\n",
    "\n",
    "#### Lab 5\n",
    "\n",
    "In [Lab 5](https://github.com/PeterAltmann/SSIdemo/blob/main/LAB5.md), we take a closer look at revocation.\n",
    "\n",
    "#### Additional optional labs\n",
    "\n",
    "* The OpenAPI demo that exists in the [ACA-Py github demo folder](https://github.com/hyperledger/aries-cloudagent-python/blob/main/demo/AriesOpenAPIDemo.md). \n",
    "* How JSON-LD VC formats signed with BBS+. Source (https://github.com/hyperledger/aries-cloudagent-python/blob/main/demo/AliceWantsAJsonCredential.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497aa74f-f2c7-4ff4-ae7c-5462f4af9051",
   "metadata": {},
   "source": [
    "## The proof of business case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb13adde-202f-46e5-93ea-9df38ca3d057",
   "metadata": {},
   "source": [
    "The following demo was developed to help the Swedish Company Registration Offices learn about VC and the various architecture components of EBSI. The demo uses Aries, Indy, and Ursa and ACA-Py, a choice motivated by the present lack of suitability in EBSI for early development and proof of concepts. With Aries, Indy, and Ursa, access is given to:\n",
    "\n",
    "1. a VDR specifically designed for digital identity data so that we do not have to create things at the DID registry level\n",
    "2. a commonly used DID method that works with our VDR\n",
    "3. a solution with a proven deployment\n",
    "4. a well documented solution with a lot of open information and guides\n",
    "\n",
    "### ToIP layer 1 choices\n",
    "For our purposes, the British Colombia (BC) project \"The Verifiable Organizations Network\" ([VON](https://vonx.io/)) checks all boxes. It builds on Hyperledger Indy, a purpose built VDR for identity. It uses `sov` as a DID Method, which works well with the Indy VDR. The potential has been successfully demonstrated resulting in a [deployed network](https://sovrin-mainnet-browser.vonx.io/) and a [data registry containing organization identifiers](https://orgbook.gov.bc.ca/search). Finally, the BC team has documented their results and prepared docker containers for easy concept testing:\n",
    "\n",
    "* The [von network github](https://github.com/bcgov/von-network)\n",
    "* The [OrgBook credential registry github](https://github.com/bcgov/TheOrgBook)\n",
    "* The [GreenLight decentralized workflow github](https://github.com/bcgov/greenlight)\n",
    "\n",
    "### ToIP layer 2 choices\n",
    "\n",
    "Today, there is really only one viable basis for an easy POC environment: [Hyperledger Aries](https://www.hyperledger.org/use/aries#:~:text=Hyperledger%20Aries%20provides%20a%20shared,peer%2Dto%2Dpeer%20interactions.). Aries provides a toolkit designed for agent interactions centered around verifiable digital credentials. Aries provides a full suite of protocols required for every possible interaction and contains a full set of protocols to support multiple different Verifiable Credential formats (including those with advanced privacy and user control features as compared [here](https://github.com/PeterAltmann/SSIdemo/blob/main/VC_formats/Verifiable-Credentials-Flavors-Explained-Infographic.pdf)). While there are many emerging options, none are as well described by community implementations as is the Aries based proof of concepts. \n",
    "\n",
    "Aries also loads Hyperledger Ursa, a complete cryptography library for functions and algorithms. As aforementioned, EBSI currently has very poor support for cryptographic algorithms and primitives that we need to demonstrate UCAD.\n",
    "\n",
    "### ToIP layer 3 choices\n",
    "\n",
    "While many parts of the credential exchange is specified in Aries, we must agree on the specific credential format to use. There are [three options listed](https://www.w3.org/TR/vc-imp-guide/#proof-formats) by W3C, and there is the additional option of AnonCreds. Each option has benefits and drawbacks.\n",
    "\n",
    "**JSON-JWT**\n",
    "\n",
    "* Simplest solution\n",
    "    * Attributes are stored as key value pairs\n",
    "* Lacks privacy features\n",
    "* Lacks semantic interoperability\n",
    "\n",
    "**JSON-LD with LD signature**\n",
    "\n",
    "* Relatively simple\n",
    "    * Attributes are stored as key value pairs\n",
    "    * Schema is stored anywhere\n",
    "* Lacks privacy features\n",
    "* Provides semantic interoperability using a `@context` and pointers for each key. Time consuming to construct.\n",
    "\n",
    "**ZKP-CL**\n",
    "\n",
    "* Very complicated with several components\n",
    "    * Attributes are stored as key value pairs\n",
    "    * Definitions are stored on VDR\n",
    "    * Schema is stored on VDR\n",
    "* Privacy features\n",
    "    * Selective disclosure\n",
    "    * Derivation\n",
    "    * Anti correlation\n",
    "* Lacks semantic interoperability\n",
    "\n",
    "**JSON-LD ZKP with BBS+**\n",
    "\n",
    "* Complicated\n",
    "    * Attributes are stored as key value pairs\n",
    "    * Schema is stored anywhere\n",
    "* Privacy features\n",
    "    * Selective disclosure\n",
    "    * Derivation theoretically possible but no wide spread implementation yet\n",
    "    * Anti correlation\n",
    "* Provides semantic interoperability using a `@context` and pointers for each key. Time consuming to construct.\n",
    "\n",
    "Note that the W3C specifications do not include **ZKP-CL**. However, **ZKP-CL** is the most commonly adopted VC format due to its early support (it was the first credential format). So, we will start with ZKP-CL simply because it is what the AnonCreds format uses. The AnonCreds format is the oldest and most well documented of the VC formats that supporWhilet enhanced privacy features. While complicated, most of the complicated features are handled by Indy and Aries. We will also look at the JSON-LD ZKP with BBS+ format. It is supported by the W3C standard and it has several important privacy features. It is also likely to be the format that the DIF / W3C community will lend most support to. It is a bit harder to implement than AnonCreds because we have to rely on linked data principles, which take a lot of time.\n",
    "\n",
    "AnonCreds will help us understand Layer 1 well. It will also help us understand the possible uses of a VDR in credential exchanges. Since Indy, Aries, and Ursa handle a lot of the complicated aspects of ZKP-CL, we can start experimenting and demoing early since we only need to define simple key value pairs for our attributes. AnonCreds can also help us understand a lot about the more advanced privacy features. However, AnonCreds are not listed on W3C as a supported credential format. JSON-LD ZKP with BBs+ is. We will therefore also explore that format. And neither ZKP-CL or BBS+ is supported by EBSI or eIDAS and support is unlikely (although eIDAS is currently looking into the possibility of having BBS+ and ZKP-CL mentioned as allowed but not mandatory).\n",
    "\n",
    "### Choice of Aries framework\n",
    "\n",
    "The protocol specifications in Aries are quite extensive ([index on github](https://github.com/hyperledger/aries-rfcs/blob/main/index.md)). To work with the protocols, we will use an Aries framework, which implements several of the protocols and makes it easier to develop a wallet.\n",
    "\n",
    "There exist multiple different frameworks (a complete list can be found [here](http://aries-interop.info/)). Our choice is informed by:\n",
    "\n",
    "* We would prefer a solution that supports both AIP 1 and AIP 2 (Aries Interoperability Profiles). \n",
    "    * The AnonCreds format is in AIP 1. \n",
    "    * The W3C format is in AIP 2. \n",
    "* We need something focused on enterprise wallets\n",
    "* We want something that is well documented\n",
    "* I am most comfortable with Python\n",
    "\n",
    "The ACA-Py (Aries Cloud Agent Python) framework supports both AIP 1 and AIP 2 and is specifically designed for cloud environments. It has a very extensive documentation since it is featured both in the BC project (they contributed the initial implementation) and it is part of the Hyperledger course [LFS173x](https://training.linuxfoundation.org/training/becoming-a-hyperledger-aries-developer-lfs173/).\n",
    "\n",
    "With ACA-Py we will have an agent framework that handles the various Aries protocols (content focused) we need, as well as the various DIDCom protocols (delivery focused) we need.\n",
    "\n",
    "<img src = 'fig/agent-controller.png' width=\"400\">\n",
    "\n",
    "The ACA-Py agent instance implements parts of the Aries framework, specifically it:\n",
    "\n",
    "1. Determines the connection type\n",
    "2. Creates protocol state objects\n",
    "3. Stores protocol state objects\n",
    "4. Sends webhooks about states and state changes\n",
    "\n",
    "The controller receives events and posts requests to the ACA-Py agent instance using REST API. It:\n",
    "\n",
    "1. Encodes the business logic that defines how different state objects should be handled (eg., what to do when a credential offer is received).\n",
    "2. Retrieves information from the protocol\n",
    "3. Constructs and sends HTTP requests to the ACA-Py administrative endpoint.\n",
    "\n",
    "Below is a high level schematic of the various solution components and how Aries, Ursa and Indy together enable verifiable data exchanges.\n",
    "\n",
    "<img src = 'fig/hl-platform.png' width=\"900\">\n",
    "\n",
    "And finally, a note on standards used:\n",
    "\n",
    "<img src='fig/toip-standards.png' width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e71c45-a490-44fa-831d-cb86624d7bbb",
   "metadata": {},
   "source": [
    "The demo is uploaded as a separate file and can be found here: https://github.com/PeterAltmann/SSIdemo/blob/main/BV-demo/Bolagsverket-demo.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
